{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ASd9OxsFzKiV"
   },
   "outputs": [],
   "source": [
    "# Import pandas as 'pd' and create an empty DataFrame with specified column names\n",
    "import pandas as pd\n",
    "\n",
    "columns = ['Search', 'video_id', 'comment_id', 'text', 'author', 'date', 'like_count', 'reply_count']\n",
    "df = pd.DataFrame(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching comments for video xqyUdNxWazA\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=xqyUdNxWazA&textFormat=plainText&maxResults=100&key=AIzaSyA2_t4gEE2zwvMRhrQyvZx4mAVaucMapeE&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\">\n",
      "Fetching comments for video pV0ud2B8WfQ\n",
      "Fetching comments for video HmBo6V7wx8E\n",
      "Fetching comments for video j3J9cIRXN9c\n",
      "Fetching comments for video Uqx4DL1pd9w\n",
      "Fetching comments for video V4D49YYihQI\n",
      "Fetching comments for video fODv2jXRY-M\n",
      "Fetching comments for video M2IfmcypfB8\n",
      "Fetching comments for video 8Og7C6RVMOs\n",
      "Fetching comments for video 2U7iiQc8eIg\n",
      "Fetching comments for video pp7rDdo2__0\n",
      "Fetching comments for video sxS9rUaKZFE\n",
      "Fetching comments for video _Bwv9Q8oKck\n",
      "Fetching comments for video 79pOjZQ2GvQ\n",
      "Fetching comments for video CuxZK8r79og\n",
      "Fetching comments for video FBxGueunDpc\n",
      "Fetching comments for video 6G71VK90teo\n",
      "Fetching comments for video yonX6PqMdik\n",
      "Fetching comments for video wSev7vQZuDk\n",
      "Fetching comments for video pmFuQ4SSHoU\n",
      "Fetching comments for video AxboAkg5o9w\n",
      "Fetching comments for video zC2-gt08vkI\n",
      "Fetching comments for video lkEDinDrVSs\n",
      "An error occurred: <HttpError 400 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=lkEDinDrVSs&textFormat=plainText&maxResults=100&pageToken=Z2V0X25ld2VzdF9maXJzdC0tQ2dnSWdBUVZGN2ZST0JJRkNJY2dHQUFTQlFpSklCZ0FFZ1VJblNBWUFSSUZDSWdnR0FBWUFDSU9DZ3dJby16TXFRWVE2TmJqN0FF&key=AIzaSyA2_t4gEE2zwvMRhrQyvZx4mAVaucMapeE&alt=json returned \"The API server failed to successfully process the request. While this can be a transient error, it usually indicates that the request's input is invalid. Check the structure of the <code>commentThread</code> resource in the request body to ensure that it is valid.\">\n",
      "Fetching comments for video oGwvJ59llcQ\n",
      "Fetching comments for video e77mwOlmEyM\n",
      "Fetching comments for video DZeMwLLqsi0\n",
      "Fetching comments for video QFFYARNPzxY\n",
      "Fetching comments for video -z7tiYqVSRU\n",
      "Fetching comments for video FNnK1J-BdiM\n",
      "Fetching comments for video Z0E1evKQicg\n",
      "Fetching comments for video 9Y2aj6n1a1M\n",
      "Fetching comments for video OG_hUSWBlBA\n",
      "Fetching comments for video _MupR4s1TwY\n",
      "Fetching comments for video aceugjqBIN0\n",
      "Fetching comments for video PsKSWAJzpbg\n",
      "Fetching comments for video XHTrLYShBRQ\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=XHTrLYShBRQ&textFormat=plainText&maxResults=100&key=AIzaSyA2_t4gEE2zwvMRhrQyvZx4mAVaucMapeE&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\">\n",
      "Fetching comments for video 8Ewd7qlyOOQ\n",
      "Fetching comments for video DfTE7jYUQ70\n",
      "Fetching comments for video Z7iBFklVU_I\n",
      "Fetching comments for video NcQVI3cv_hY\n",
      "Fetching comments for video jeZ7XhD4mF0\n",
      "Fetching comments for video pdXMSSUQ17k\n",
      "Fetching comments for video --dch8Brxrk\n",
      "Fetching comments for video UWLUMFRade0\n",
      "Fetching comments for video c9M94-zJEDA\n",
      "Fetching comments for video w_JEezynhrc\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=w_JEezynhrc&textFormat=plainText&maxResults=100&key=AIzaSyA2_t4gEE2zwvMRhrQyvZx4mAVaucMapeE&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\">\n",
      "Fetching comments for video 2m6URTkMHfI\n",
      "Fetching comments for video FUlbDPlbPaQ\n",
      "Fetching comments for video PjjkemXM32Y\n",
      "Fetching comments for video oNfboeqRtTA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search</th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgwuZ0IvcR2eBzmPwax4AaABAg</td>\n",
       "      <td>iPhone 4s was the perfect size.</td>\n",
       "      <td>Carlos Vega</td>\n",
       "      <td>2023-11-07T04:49:36Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgzguuMuaAx24szlaAp4AaABAg</td>\n",
       "      <td>I went from the iPhone 3GS to 4 to 4S to 5 to ...</td>\n",
       "      <td>user</td>\n",
       "      <td>2023-11-06T22:33:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgyGaqW4zXg9OvvN9014AaABAg</td>\n",
       "      <td>Beginning 0:01\\niPhone 0:02\\niPhone 3G 0:13\\ni...</td>\n",
       "      <td>iPhone 5s</td>\n",
       "      <td>2023-11-06T00:48:43Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgzbV3ptoU69pXWsJ-V4AaABAg</td>\n",
       "      <td>My evolution of owning an iPhone \\n3Gs\\n4s\\n5s...</td>\n",
       "      <td>Sunshine19</td>\n",
       "      <td>2023-10-29T22:29:27Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>Ugx7_-E4N4MVG3oN2q14AaABAg</td>\n",
       "      <td>Every iPhone: Our subtitles are revolations!\\n...</td>\n",
       "      <td>J-D Flash Studios { Discontinued }</td>\n",
       "      <td>2023-10-29T14:14:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16133</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>PjjkemXM32Y</td>\n",
       "      <td>Ugz9yHrDeqMQyrlElqF4AaABAg</td>\n",
       "      <td>Никакой IPhone не нужен!</td>\n",
       "      <td>Александр Стецурин</td>\n",
       "      <td>2022-11-13T19:55:17Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16134</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>PjjkemXM32Y</td>\n",
       "      <td>UgzOKrFvtcIbOchBnYp4AaABAg</td>\n",
       "      <td>Я: покупаю iPhone 14 \\nДрузья: о у тебя iPhone...</td>\n",
       "      <td>Cagoniro</td>\n",
       "      <td>2022-11-13T17:08:36Z</td>\n",
       "      <td>4012</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16135</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>PjjkemXM32Y</td>\n",
       "      <td>UgxVJMpzW3VMsR5qx1h4AaABAg</td>\n",
       "      <td>А где новая чёлка в 14 iPhone ?</td>\n",
       "      <td>Sideremy</td>\n",
       "      <td>2022-11-13T10:36:25Z</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16136</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>oNfboeqRtTA</td>\n",
       "      <td>UgwGjSMle3ylO8KBjc14AaABAg</td>\n",
       "      <td>iPhone15Pro MAXって20万?ぐらいするんですよ!?\\nマジ凄すぎワロタｧｧｧｧ...</td>\n",
       "      <td>keikachinshu1006</td>\n",
       "      <td>2023-10-15T01:10:29Z</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16137</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>oNfboeqRtTA</td>\n",
       "      <td>UgxPhZFjAlsadsVYrMV4AaABAg</td>\n",
       "      <td>iPhoneめっちゃ良いですね✨</td>\n",
       "      <td>kazuhalove aaa</td>\n",
       "      <td>2023-10-14T09:53:13Z</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15984 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Search     video_id                  comment_id  \\\n",
       "0      iPhone  pV0ud2B8WfQ  UgwuZ0IvcR2eBzmPwax4AaABAg   \n",
       "1      iPhone  pV0ud2B8WfQ  UgzguuMuaAx24szlaAp4AaABAg   \n",
       "2      iPhone  pV0ud2B8WfQ  UgyGaqW4zXg9OvvN9014AaABAg   \n",
       "3      iPhone  pV0ud2B8WfQ  UgzbV3ptoU69pXWsJ-V4AaABAg   \n",
       "4      iPhone  pV0ud2B8WfQ  Ugx7_-E4N4MVG3oN2q14AaABAg   \n",
       "...       ...          ...                         ...   \n",
       "16133  iPhone  PjjkemXM32Y  Ugz9yHrDeqMQyrlElqF4AaABAg   \n",
       "16134  iPhone  PjjkemXM32Y  UgzOKrFvtcIbOchBnYp4AaABAg   \n",
       "16135  iPhone  PjjkemXM32Y  UgxVJMpzW3VMsR5qx1h4AaABAg   \n",
       "16136  iPhone  oNfboeqRtTA  UgwGjSMle3ylO8KBjc14AaABAg   \n",
       "16137  iPhone  oNfboeqRtTA  UgxPhZFjAlsadsVYrMV4AaABAg   \n",
       "\n",
       "                                                    text  \\\n",
       "0                        iPhone 4s was the perfect size.   \n",
       "1      I went from the iPhone 3GS to 4 to 4S to 5 to ...   \n",
       "2      Beginning 0:01\\niPhone 0:02\\niPhone 3G 0:13\\ni...   \n",
       "3      My evolution of owning an iPhone \\n3Gs\\n4s\\n5s...   \n",
       "4      Every iPhone: Our subtitles are revolations!\\n...   \n",
       "...                                                  ...   \n",
       "16133                           Никакой IPhone не нужен!   \n",
       "16134  Я: покупаю iPhone 14 \\nДрузья: о у тебя iPhone...   \n",
       "16135                    А где новая чёлка в 14 iPhone ?   \n",
       "16136  iPhone15Pro MAXって20万?ぐらいするんですよ!?\\nマジ凄すぎワロタｧｧｧｧ...   \n",
       "16137                                   iPhoneめっちゃ良いですね✨   \n",
       "\n",
       "                                   author                  date like_count  \\\n",
       "0                             Carlos Vega  2023-11-07T04:49:36Z          0   \n",
       "1                                    user  2023-11-06T22:33:16Z          0   \n",
       "2                               iPhone 5s  2023-11-06T00:48:43Z          1   \n",
       "3                              Sunshine19  2023-10-29T22:29:27Z          0   \n",
       "4      J-D Flash Studios { Discontinued }  2023-10-29T14:14:16Z          0   \n",
       "...                                   ...                   ...        ...   \n",
       "16133                  Александр Стецурин  2022-11-13T19:55:17Z          0   \n",
       "16134                            Cagoniro  2022-11-13T17:08:36Z       4012   \n",
       "16135                           Sideremy   2022-11-13T10:36:25Z          0   \n",
       "16136                    keikachinshu1006  2023-10-15T01:10:29Z          3   \n",
       "16137                      kazuhalove aaa  2023-10-14T09:53:13Z          6   \n",
       "\n",
       "      reply_count  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "16133           1  \n",
       "16134          43  \n",
       "16135           4  \n",
       "16136           0  \n",
       "16137           0  \n",
       "\n",
       "[15984 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This script uses the YouTube Data API to search for videos, retrieve comments, and store them in a Pandas DataFrame\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "api_key = 'AIzaSyA2_t4gEE2zwvMRhrQyvZx4mAVaucMapeE'  \n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "def search_videos(youtube, query, max_results):\n",
    "    search_response = youtube.search().list(\n",
    "        q=query,\n",
    "        part='id',\n",
    "        maxResults=max_results,\n",
    "        type='video'\n",
    "    ).execute()\n",
    "\n",
    "    video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "    return video_ids\n",
    "\n",
    "def get_comments(youtube, video_id):\n",
    "    comments_data = []\n",
    "    try:\n",
    "        page_token = None\n",
    "        while True:\n",
    "            response = youtube.commentThreads().list(\n",
    "                part='snippet,replies',\n",
    "                videoId=video_id,\n",
    "                textFormat='plainText',\n",
    "                maxResults=100,\n",
    "                pageToken=page_token\n",
    "            ).execute()\n",
    "\n",
    "            for item in response['items']:\n",
    "                top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "                comments_data.append({\n",
    "                    'video_id': video_id,\n",
    "                    'comment_id': item['id'],\n",
    "                    'text': top_comment['textDisplay'],\n",
    "                    'author': top_comment['authorDisplayName'],\n",
    "                    'date': top_comment['publishedAt'],\n",
    "                    'like_count': top_comment['likeCount'],\n",
    "                    'reply_count': item['snippet']['totalReplyCount']\n",
    "                })\n",
    "\n",
    "            page_token = response.get('nextPageToken')\n",
    "            if not page_token:\n",
    "                break\n",
    "\n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "    return comments_data\n",
    "\n",
    "video_ids = search_videos(youtube, \"iPhone\", 100)\n",
    "\n",
    "all_comments = []\n",
    "for video_id in video_ids:\n",
    "    print(f'Fetching comments for video {video_id}')\n",
    "    comments = get_comments(youtube, video_id)\n",
    "    all_comments.extend(comments)\n",
    "\n",
    "temp_df = pd.DataFrame(all_comments)\n",
    "\n",
    "temp_df = temp_df[temp_df['text'].str.contains(\"iPhone\", case=False)]\n",
    "\n",
    "temp_df = temp_df.dropna(subset=['text'])\n",
    "\n",
    "temp_df['Search'] = 'iPhone'\n",
    "\n",
    "df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "df = df.dropna(subset=['text']).drop_duplicates(subset=['text'])\n",
    "\n",
    "df.to_csv('youtube_comments.csv', index=False)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 / 50\n",
      "Fetching comments for video 6yJDWshMZuo\n",
      "35 / 50\n",
      "Fetching comments for video WAXqB0CIXrU\n",
      "36 / 50\n",
      "Fetching comments for video KqD2JKDLkhU\n",
      "37 / 50\n",
      "Fetching comments for video 934V2eiwsNA\n",
      "38 / 50\n",
      "Fetching comments for video a500SZyQFxQ\n",
      "39 / 50\n",
      "Fetching comments for video jtdDpryUte8\n",
      "40 / 50\n",
      "Fetching comments for video 8RIgnWd50dY\n",
      "41 / 50\n",
      "Fetching comments for video kjSAYk9tuHw\n",
      "42 / 50\n",
      "Fetching comments for video JloOtpv-Wv8\n",
      "43 / 50\n",
      "Fetching comments for video qlqP1q9doWo\n",
      "44 / 50\n",
      "Fetching comments for video 50fqpXh0FO8\n",
      "45 / 50\n",
      "Fetching comments for video wiDoluB69c8\n",
      "46 / 50\n",
      "Fetching comments for video d-GPnbzx87Y\n",
      "47 / 50\n",
      "Fetching comments for video c3W3iKb5o2I\n",
      "48 / 50\n",
      "Fetching comments for video 7MQnkq1zIZ0\n",
      "49 / 50\n",
      "Fetching comments for video MZLlPvDYxME\n",
      "50 / 50\n",
      "Fetching comments for video Zet21G4RVeU\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search</th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgwuZ0IvcR2eBzmPwax4AaABAg</td>\n",
       "      <td>iPhone 4s was the perfect size.</td>\n",
       "      <td>Carlos Vega</td>\n",
       "      <td>2023-11-07T04:49:36Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgzguuMuaAx24szlaAp4AaABAg</td>\n",
       "      <td>I went from the iPhone 3GS to 4 to 4S to 5 to ...</td>\n",
       "      <td>user</td>\n",
       "      <td>2023-11-06T22:33:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgyGaqW4zXg9OvvN9014AaABAg</td>\n",
       "      <td>Beginning 0:01\\niPhone 0:02\\niPhone 3G 0:13\\ni...</td>\n",
       "      <td>iPhone 5s</td>\n",
       "      <td>2023-11-06T00:48:43Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgzbV3ptoU69pXWsJ-V4AaABAg</td>\n",
       "      <td>My evolution of owning an iPhone \\n3Gs\\n4s\\n5s...</td>\n",
       "      <td>Sunshine19</td>\n",
       "      <td>2023-10-29T22:29:27Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>Ugx7_-E4N4MVG3oN2q14AaABAg</td>\n",
       "      <td>Every iPhone: Our subtitles are revolations!\\n...</td>\n",
       "      <td>J-D Flash Studios { Discontinued }</td>\n",
       "      <td>2023-10-29T14:14:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21492</th>\n",
       "      <td>AirPods</td>\n",
       "      <td>Zet21G4RVeU</td>\n",
       "      <td>Ugy25Wb6-WzNtoPBNNF4AaABAg</td>\n",
       "      <td>Nice ill hope i have it. For now i using bavin...</td>\n",
       "      <td>Felo</td>\n",
       "      <td>2023-07-26T11:58:40Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21493</th>\n",
       "      <td>AirPods</td>\n",
       "      <td>Zet21G4RVeU</td>\n",
       "      <td>UgwNsSBMjR2-D15LA8p4AaABAg</td>\n",
       "      <td>2079: unboxing AirPods Pro max plus from 2029</td>\n",
       "      <td>Crosante Cotino</td>\n",
       "      <td>2023-07-22T00:23:55Z</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21494</th>\n",
       "      <td>AirPods</td>\n",
       "      <td>Zet21G4RVeU</td>\n",
       "      <td>Ugz5ErqYp6IA9FtVyhV4AaABAg</td>\n",
       "      <td>Those were the first ones I ever got. Then the...</td>\n",
       "      <td>JaymanPro07</td>\n",
       "      <td>2023-07-20T22:24:25Z</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21495</th>\n",
       "      <td>AirPods</td>\n",
       "      <td>Zet21G4RVeU</td>\n",
       "      <td>UgwkQ81-kal3XNAHH0x4AaABAg</td>\n",
       "      <td>I have the airpod pros gen 2 and they sound go...</td>\n",
       "      <td>Donutlover</td>\n",
       "      <td>2023-07-12T00:47:35Z</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21496</th>\n",
       "      <td>AirPods</td>\n",
       "      <td>Zet21G4RVeU</td>\n",
       "      <td>UgzHBhwlWeaXk9_SzvN4AaABAg</td>\n",
       "      <td>This is not airpods 2 :? Cuz the light is insi...</td>\n",
       "      <td>Tech Videos</td>\n",
       "      <td>2023-06-21T01:04:07Z</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18829 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Search     video_id                  comment_id  \\\n",
       "0       iPhone  pV0ud2B8WfQ  UgwuZ0IvcR2eBzmPwax4AaABAg   \n",
       "1       iPhone  pV0ud2B8WfQ  UgzguuMuaAx24szlaAp4AaABAg   \n",
       "2       iPhone  pV0ud2B8WfQ  UgyGaqW4zXg9OvvN9014AaABAg   \n",
       "3       iPhone  pV0ud2B8WfQ  UgzbV3ptoU69pXWsJ-V4AaABAg   \n",
       "4       iPhone  pV0ud2B8WfQ  Ugx7_-E4N4MVG3oN2q14AaABAg   \n",
       "...        ...          ...                         ...   \n",
       "21492  AirPods  Zet21G4RVeU  Ugy25Wb6-WzNtoPBNNF4AaABAg   \n",
       "21493  AirPods  Zet21G4RVeU  UgwNsSBMjR2-D15LA8p4AaABAg   \n",
       "21494  AirPods  Zet21G4RVeU  Ugz5ErqYp6IA9FtVyhV4AaABAg   \n",
       "21495  AirPods  Zet21G4RVeU  UgwkQ81-kal3XNAHH0x4AaABAg   \n",
       "21496  AirPods  Zet21G4RVeU  UgzHBhwlWeaXk9_SzvN4AaABAg   \n",
       "\n",
       "                                                    text  \\\n",
       "0                        iPhone 4s was the perfect size.   \n",
       "1      I went from the iPhone 3GS to 4 to 4S to 5 to ...   \n",
       "2      Beginning 0:01\\niPhone 0:02\\niPhone 3G 0:13\\ni...   \n",
       "3      My evolution of owning an iPhone \\n3Gs\\n4s\\n5s...   \n",
       "4      Every iPhone: Our subtitles are revolations!\\n...   \n",
       "...                                                  ...   \n",
       "21492  Nice ill hope i have it. For now i using bavin...   \n",
       "21493      2079: unboxing AirPods Pro max plus from 2029   \n",
       "21494  Those were the first ones I ever got. Then the...   \n",
       "21495  I have the airpod pros gen 2 and they sound go...   \n",
       "21496  This is not airpods 2 :? Cuz the light is insi...   \n",
       "\n",
       "                                   author                  date like_count  \\\n",
       "0                             Carlos Vega  2023-11-07T04:49:36Z          0   \n",
       "1                                    user  2023-11-06T22:33:16Z          0   \n",
       "2                               iPhone 5s  2023-11-06T00:48:43Z          1   \n",
       "3                              Sunshine19  2023-10-29T22:29:27Z          0   \n",
       "4      J-D Flash Studios { Discontinued }  2023-10-29T14:14:16Z          0   \n",
       "...                                   ...                   ...        ...   \n",
       "21492                                Felo  2023-07-26T11:58:40Z          1   \n",
       "21493                     Crosante Cotino  2023-07-22T00:23:55Z         39   \n",
       "21494                         JaymanPro07  2023-07-20T22:24:25Z         24   \n",
       "21495                          Donutlover  2023-07-12T00:47:35Z          2   \n",
       "21496                         Tech Videos  2023-06-21T01:04:07Z         11   \n",
       "\n",
       "      reply_count  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "21492           0  \n",
       "21493           2  \n",
       "21494           6  \n",
       "21495           1  \n",
       "21496           8  \n",
       "\n",
       "[18829 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules from the Google API client library\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Initialize the YouTube API client\n",
    "api_key = 'AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4'  # Replace with your API key\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Function to search for videos using the YouTube API\n",
    "def search_videos(youtube, query, max_results):\n",
    "    # Make a search request to the API with the given parameters\n",
    "    search_response = youtube.search().list(\n",
    "        q=query,\n",
    "        part='id',\n",
    "        maxResults=max_results,\n",
    "        type='video'\n",
    "    ).execute()\n",
    "    \n",
    "    # Extract video IDs from the search response\n",
    "    video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "    return video_ids\n",
    "\n",
    "# Function to retrieve comments for a given video ID using the YouTube API\n",
    "def get_comments(youtube, video_id):\n",
    "    comments_data = []\n",
    "    try:\n",
    "        # Loop through pages of comments using pagination\n",
    "        page_token = None\n",
    "        while True:\n",
    "            response = youtube.commentThreads().list(\n",
    "                part='snippet,replies',\n",
    "                videoId=video_id,\n",
    "                textFormat='plainText',\n",
    "                maxResults=100,\n",
    "                pageToken=page_token\n",
    "            ).execute()\n",
    "\n",
    "            # Extract relevant information from each comment and its replies\n",
    "            for item in response['items']:\n",
    "                top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "                comments_data.append({\n",
    "                    'video_id': video_id,\n",
    "                    'comment_id': item['id'],\n",
    "                    'text': top_comment['textDisplay'],\n",
    "                    'author': top_comment['authorDisplayName'],\n",
    "                    'date': top_comment['publishedAt'],\n",
    "                    'like_count': top_comment['likeCount'],\n",
    "                    'reply_count': item['snippet']['totalReplyCount']\n",
    "                })\n",
    "\n",
    "            # Check if there are more pages of comments\n",
    "            page_token = response.get('nextPageToken')\n",
    "            if not page_token:\n",
    "                break\n",
    "\n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "    return comments_data\n",
    "\n",
    "# Search for videos with the keyword \"AirPods\"\n",
    "video_ids = search_videos(youtube, \"AirPods\", 100)\n",
    "\n",
    "# Collect comments from each video\n",
    "all_comments = []\n",
    "\n",
    "# Iterate through the video IDs starting from index 33\n",
    "for video_id in range(33, len(video_ids)):\n",
    "    print(f'{video_id + 1} / {len(video_ids)}')\n",
    "    print(f'Fetching comments for video {video_ids[video_id]}')\n",
    "    \n",
    "    # Retrieve comments for the current video ID\n",
    "    comments = get_comments(youtube, video_ids[video_id])\n",
    "    \n",
    "    # Extend the list of all comments with the comments from the current video\n",
    "    all_comments.extend(comments)\n",
    "    \n",
    "    # Create a temporary Pandas DataFrame from the collected comments\n",
    "    temp_df = pd.DataFrame(all_comments)\n",
    "    \n",
    "    # Filter comments containing the word \"AirPods\" (case-insensitive)\n",
    "    temp_df = temp_df[temp_df['text'].str.contains(\"AirPods\", case=False)]\n",
    "    \n",
    "    # Drop rows with missing text values\n",
    "    temp_df = temp_df.dropna(subset=['text'])\n",
    "    \n",
    "    # Add a 'Search' column with the value 'AirPods'\n",
    "    temp_df['Search'] = 'AirPods'\n",
    "    \n",
    "    # Concatenate the temporary DataFrame with the existing DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    \n",
    "    # Drop rows with missing text values and remove duplicate comments\n",
    "    df = df.dropna(subset=['text']).drop_duplicates(subset=['text'])\n",
    "    \n",
    "    # Save the DataFrame to a CSV file named 'youtube_comments.csv'\n",
    "    df.to_csv('youtube_comments.csv', index=False)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPhone     15984\n",
       "AirPods      253\n",
       "Name: Search, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each unique Apple product\n",
    "df.Search.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 50\n",
      "Fetching comments for video FYxUJFD9Ye4\n",
      "2 / 50\n",
      "Fetching comments for video A8e5jbiwMXI\n",
      "3 / 50\n",
      "Fetching comments for video pwHNannxolo\n",
      "4 / 50\n",
      "Fetching comments for video vWoe-jTLExE\n",
      "5 / 50\n",
      "Fetching comments for video A5mMaChwCog\n",
      "6 / 50\n",
      "Fetching comments for video YQReKkSC5fE\n",
      "7 / 50\n",
      "Fetching comments for video fY6y8wnixW8\n",
      "8 / 50\n",
      "Fetching comments for video KVI0xftOBvA\n",
      "9 / 50\n",
      "Fetching comments for video ujJEEJTrI1Y\n",
      "10 / 50\n",
      "Fetching comments for video CwtUJ30A8nY\n",
      "11 / 50\n",
      "Fetching comments for video fS06w93bmMg\n",
      "12 / 50\n",
      "Fetching comments for video nZtyJVRTUNE\n",
      "13 / 50\n",
      "Fetching comments for video mQD1JiefSxw\n",
      "14 / 50\n",
      "Fetching comments for video yzMnJ353uBw\n",
      "15 / 50\n",
      "Fetching comments for video 74VHzCaaIZo\n",
      "16 / 50\n",
      "Fetching comments for video gjnb6u7pSiw\n",
      "17 / 50\n",
      "Fetching comments for video V8hp_iDhdZU\n",
      "18 / 50\n",
      "Fetching comments for video phGlO0Lt-Tk\n",
      "19 / 50\n",
      "Fetching comments for video V2S-aHWeQcc\n",
      "20 / 50\n",
      "Fetching comments for video PSRMwwlO8Es\n",
      "21 / 50\n",
      "Fetching comments for video qh14a1oCi8c\n",
      "22 / 50\n",
      "Fetching comments for video OY7czl1VBaM\n",
      "23 / 50\n",
      "Fetching comments for video afy0WUfwDWU\n",
      "24 / 50\n",
      "Fetching comments for video yXwYtZ2RxtE\n",
      "25 / 50\n",
      "Fetching comments for video O_WbmIIy4vk\n",
      "26 / 50\n",
      "Fetching comments for video pzAy-iFA5r0\n",
      "27 / 50\n",
      "Fetching comments for video l2s2XNbk3NA\n",
      "28 / 50\n",
      "Fetching comments for video xpc1uyI6aDw\n",
      "29 / 50\n",
      "Fetching comments for video mRVN-Dfw3Ec\n",
      "30 / 50\n",
      "Fetching comments for video FM8NBDYxsQo\n",
      "31 / 50\n",
      "Fetching comments for video fA1cMYCrQfM\n",
      "32 / 50\n",
      "Fetching comments for video 57FsXREfhVo\n",
      "33 / 50\n",
      "Fetching comments for video bUJSG7jas4Y\n",
      "34 / 50\n",
      "Fetching comments for video I3zUpWYLpoQ\n",
      "35 / 50\n",
      "Fetching comments for video -zZErxh2p4Q\n",
      "36 / 50\n",
      "Fetching comments for video hJ5Fi0GiHUQ\n",
      "37 / 50\n",
      "Fetching comments for video sIzCq_2vwQo\n",
      "38 / 50\n",
      "Fetching comments for video io8PNBmBncE\n",
      "39 / 50\n",
      "Fetching comments for video HjT9tMCIaLE\n",
      "40 / 50\n",
      "Fetching comments for video w-z6oylaykE\n",
      "41 / 50\n",
      "Fetching comments for video 3xBAHvKzAP0\n",
      "42 / 50\n",
      "Fetching comments for video o3bDf3o4Wz0\n",
      "43 / 50\n",
      "Fetching comments for video UoXOEbM7LNk\n",
      "44 / 50\n",
      "Fetching comments for video w9P3_TPObmU\n",
      "45 / 50\n",
      "Fetching comments for video HfJ56N0FHNY\n",
      "46 / 50\n",
      "Fetching comments for video ka57wGsgwb8\n",
      "47 / 50\n",
      "Fetching comments for video n7yeAXz9EZE\n",
      "48 / 50\n",
      "Fetching comments for video 5ED_jV2dtc4\n",
      "49 / 50\n",
      "Fetching comments for video l6KvxcWRkjI\n",
      "50 / 50\n",
      "Fetching comments for video sKBBWeRGuZs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search</th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgwuZ0IvcR2eBzmPwax4AaABAg</td>\n",
       "      <td>iPhone 4s was the perfect size.</td>\n",
       "      <td>Carlos Vega</td>\n",
       "      <td>2023-11-07T04:49:36Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgzguuMuaAx24szlaAp4AaABAg</td>\n",
       "      <td>I went from the iPhone 3GS to 4 to 4S to 5 to ...</td>\n",
       "      <td>user</td>\n",
       "      <td>2023-11-06T22:33:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgyGaqW4zXg9OvvN9014AaABAg</td>\n",
       "      <td>Beginning 0:01\\niPhone 0:02\\niPhone 3G 0:13\\ni...</td>\n",
       "      <td>iPhone 5s</td>\n",
       "      <td>2023-11-06T00:48:43Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgzbV3ptoU69pXWsJ-V4AaABAg</td>\n",
       "      <td>My evolution of owning an iPhone \\n3Gs\\n4s\\n5s...</td>\n",
       "      <td>Sunshine19</td>\n",
       "      <td>2023-10-29T22:29:27Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>Ugx7_-E4N4MVG3oN2q14AaABAg</td>\n",
       "      <td>Every iPhone: Our subtitles are revolations!\\n...</td>\n",
       "      <td>J-D Flash Studios { Discontinued }</td>\n",
       "      <td>2023-10-29T14:14:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52905</th>\n",
       "      <td>iPad</td>\n",
       "      <td>sKBBWeRGuZs</td>\n",
       "      <td>Ugw4umUqqpod0MAYXEJ4AaABAg</td>\n",
       "      <td>Apple loopt achter op concurrentie en zichzelf...</td>\n",
       "      <td>Jesse Place</td>\n",
       "      <td>2022-10-25T17:45:00Z</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52906</th>\n",
       "      <td>iPad</td>\n",
       "      <td>sKBBWeRGuZs</td>\n",
       "      <td>UgzXaLLRnLyci5ddlKJ4AaABAg</td>\n",
       "      <td>Mijn iPad gaat wel naar het beginscherm als ik...</td>\n",
       "      <td>Mikke baauw</td>\n",
       "      <td>2022-10-25T17:37:40Z</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52907</th>\n",
       "      <td>iPad</td>\n",
       "      <td>sKBBWeRGuZs</td>\n",
       "      <td>UgyLDWS6omTwhWlZCFJ4AaABAg</td>\n",
       "      <td>Het nieuwe hoesje van de iPad vind ik wel heel...</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>2022-10-25T17:33:41Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52908</th>\n",
       "      <td>iPad</td>\n",
       "      <td>sKBBWeRGuZs</td>\n",
       "      <td>UgwEdDNPu0nXY1qijoB4AaABAg</td>\n",
       "      <td>Als Apple een 11inch iPad met OLED scherm uitb...</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>2022-10-25T17:33:10Z</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52909</th>\n",
       "      <td>iPad</td>\n",
       "      <td>sKBBWeRGuZs</td>\n",
       "      <td>UgxKJkWBJRFvMLaiEw94AaABAg</td>\n",
       "      <td>Blijft een rare keuze met die nieuwe iPad</td>\n",
       "      <td>LUCAS VDL</td>\n",
       "      <td>2022-10-25T17:31:31Z</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35789 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Search     video_id                  comment_id  \\\n",
       "0      iPhone  pV0ud2B8WfQ  UgwuZ0IvcR2eBzmPwax4AaABAg   \n",
       "1      iPhone  pV0ud2B8WfQ  UgzguuMuaAx24szlaAp4AaABAg   \n",
       "2      iPhone  pV0ud2B8WfQ  UgyGaqW4zXg9OvvN9014AaABAg   \n",
       "3      iPhone  pV0ud2B8WfQ  UgzbV3ptoU69pXWsJ-V4AaABAg   \n",
       "4      iPhone  pV0ud2B8WfQ  Ugx7_-E4N4MVG3oN2q14AaABAg   \n",
       "...       ...          ...                         ...   \n",
       "52905    iPad  sKBBWeRGuZs  Ugw4umUqqpod0MAYXEJ4AaABAg   \n",
       "52906    iPad  sKBBWeRGuZs  UgzXaLLRnLyci5ddlKJ4AaABAg   \n",
       "52907    iPad  sKBBWeRGuZs  UgyLDWS6omTwhWlZCFJ4AaABAg   \n",
       "52908    iPad  sKBBWeRGuZs  UgwEdDNPu0nXY1qijoB4AaABAg   \n",
       "52909    iPad  sKBBWeRGuZs  UgxKJkWBJRFvMLaiEw94AaABAg   \n",
       "\n",
       "                                                    text  \\\n",
       "0                        iPhone 4s was the perfect size.   \n",
       "1      I went from the iPhone 3GS to 4 to 4S to 5 to ...   \n",
       "2      Beginning 0:01\\niPhone 0:02\\niPhone 3G 0:13\\ni...   \n",
       "3      My evolution of owning an iPhone \\n3Gs\\n4s\\n5s...   \n",
       "4      Every iPhone: Our subtitles are revolations!\\n...   \n",
       "...                                                  ...   \n",
       "52905  Apple loopt achter op concurrentie en zichzelf...   \n",
       "52906  Mijn iPad gaat wel naar het beginscherm als ik...   \n",
       "52907  Het nieuwe hoesje van de iPad vind ik wel heel...   \n",
       "52908  Als Apple een 11inch iPad met OLED scherm uitb...   \n",
       "52909          Blijft een rare keuze met die nieuwe iPad   \n",
       "\n",
       "                                   author                  date like_count  \\\n",
       "0                             Carlos Vega  2023-11-07T04:49:36Z          0   \n",
       "1                                    user  2023-11-06T22:33:16Z          0   \n",
       "2                               iPhone 5s  2023-11-06T00:48:43Z          1   \n",
       "3                              Sunshine19  2023-10-29T22:29:27Z          0   \n",
       "4      J-D Flash Studios { Discontinued }  2023-10-29T14:14:16Z          0   \n",
       "...                                   ...                   ...        ...   \n",
       "52905                         Jesse Place  2022-10-25T17:45:00Z          6   \n",
       "52906                         Mikke baauw  2022-10-25T17:37:40Z          6   \n",
       "52907                              Thomas  2022-10-25T17:33:41Z          1   \n",
       "52908                              Thomas  2022-10-25T17:33:10Z          8   \n",
       "52909                           LUCAS VDL  2022-10-25T17:31:31Z          3   \n",
       "\n",
       "      reply_count  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "52905           0  \n",
       "52906           4  \n",
       "52907           1  \n",
       "52908           3  \n",
       "52909           0  \n",
       "\n",
       "[35789 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules from the Google API client library\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Replace 'api_key' with your actual YouTube Data API key\n",
    "api_key = 'AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Function to search for videos based on a query and retrieve video IDs\n",
    "def search_videos(youtube, query, max_results):\n",
    "    # Execute the search query and extract video IDs\n",
    "    search_response = youtube.search().list(\n",
    "        q=query,\n",
    "        part='id',\n",
    "        maxResults=max_results,\n",
    "        type='video'\n",
    "    ).execute()\n",
    "    video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "    return video_ids\n",
    "\n",
    "# Function to retrieve comments for a given video ID\n",
    "def get_comments(youtube, video_id):\n",
    "    comments_data = []\n",
    "    try:\n",
    "        # Iterate through pages of comments using pagination\n",
    "        page_token = None\n",
    "        while True:\n",
    "            response = youtube.commentThreads().list(\n",
    "                part='snippet,replies',\n",
    "                videoId=video_id,\n",
    "                textFormat='plainText',\n",
    "                maxResults=100,\n",
    "                pageToken=page_token\n",
    "            ).execute()\n",
    "\n",
    "            # Extract relevant information from each comment\n",
    "            for item in response['items']:\n",
    "                top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "                comments_data.append({\n",
    "                    'video_id': video_id,\n",
    "                    'comment_id': item['id'],\n",
    "                    'text': top_comment['textDisplay'],\n",
    "                    'author': top_comment['authorDisplayName'],\n",
    "                    'date': top_comment['publishedAt'],\n",
    "                    'like_count': top_comment['likeCount'],\n",
    "                    'reply_count': item['snippet']['totalReplyCount']\n",
    "                })\n",
    "\n",
    "            # Check for the presence of additional pages of comments\n",
    "            page_token = response.get('nextPageToken')\n",
    "            if not page_token:\n",
    "                break\n",
    "\n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "    return comments_data\n",
    "\n",
    "# Search for videos with the keyword \"iPad\" and retrieve video IDs\n",
    "video_ids = search_videos(youtube, \"iPad\", 100)\n",
    "\n",
    "# Collect comments from each video and filter for those containing \"iPad\"\n",
    "all_comments = []\n",
    "for video_id in range(len(video_ids)):\n",
    "    print(str(video_id+1) + \" / \" + str(len(video_ids)))\n",
    "    print(f'Fetching comments for video {video_ids[video_id]}')\n",
    "    comments = get_comments(youtube, video_ids[video_id])\n",
    "\n",
    "    # Filter comments containing the keyword \"iPad\"\n",
    "    temp_df = pd.DataFrame(all_comments)\n",
    "    temp_df = temp_df[temp_df['text'].str.contains(\"iPad\", case=False)]\n",
    "    temp_df = temp_df.dropna(subset=['text'])\n",
    "    temp_df['Search'] = 'iPad'\n",
    "    \n",
    "    # Append the filtered comments to the overall DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    df = df.dropna(subset=['text']).drop_duplicates(subset=['text'])\n",
    "\n",
    "    # Save the DataFrame to a CSV file after each iteration\n",
    "    df.to_csv('youtube_comments.csv', index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad       16960\n",
       "iPhone     15984\n",
       "AirPods     2845\n",
       "Name: Search, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each unique Apple product\n",
    "df.Search.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 50\n",
      "Fetching comments for video qie7cfjnLAY\n",
      "2 / 50\n",
      "Fetching comments for video 0pg_Y41waaE\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=0pg_Y41waaE&textFormat=plainText&maxResults=100&key=AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\">\n",
      "3 / 50\n",
      "Fetching comments for video t4ejFV6n4b8\n",
      "4 / 50\n",
      "Fetching comments for video nWtvbaMeImA\n",
      "5 / 50\n",
      "Fetching comments for video P0sVCUWJ6VU\n",
      "6 / 50\n",
      "Fetching comments for video VbaxlLZnjD4\n",
      "7 / 50\n",
      "Fetching comments for video uCNKmp4REHk\n",
      "8 / 50\n",
      "Fetching comments for video u3M1Q4TjaZQ\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=u3M1Q4TjaZQ&textFormat=plainText&maxResults=100&key=AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\">\n",
      "9 / 50\n",
      "Fetching comments for video zUyKtOj3cks\n",
      "10 / 50\n",
      "Fetching comments for video 1TCuf_Qcfv8\n",
      "11 / 50\n",
      "Fetching comments for video Xym4HPxHzjs\n",
      "12 / 50\n",
      "Fetching comments for video L-RhNLERfLE\n",
      "13 / 50\n",
      "Fetching comments for video kBZ6kW8G8Y8\n",
      "14 / 50\n",
      "Fetching comments for video kwJzKfiPHnc\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=kwJzKfiPHnc&textFormat=plainText&maxResults=100&key=AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\">\n",
      "15 / 50\n",
      "Fetching comments for video P2sz0FItyLQ\n",
      "16 / 50\n",
      "Fetching comments for video gB9yzVPfnJg\n",
      "17 / 50\n",
      "Fetching comments for video ChPG77nsYvg\n",
      "18 / 50\n",
      "Fetching comments for video tmGDx9hVWwo\n",
      "19 / 50\n",
      "Fetching comments for video LVkpNPqNIXA\n",
      "20 / 50\n",
      "Fetching comments for video 94B6mcGm8Sc\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=94B6mcGm8Sc&textFormat=plainText&maxResults=100&key=AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\">\n",
      "21 / 50\n",
      "Fetching comments for video r7COWvxlN5g\n",
      "An error occurred: <HttpError 400 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=r7COWvxlN5g&textFormat=plainText&maxResults=100&pageToken=Z2V0X25ld2VzdF9maXJzdC0tQ2dnSWdBUVZGN2ZST0JJRkNJa2dHQUFTQlFpZElCZ0JFZ1VJaUNBWUFCSUZDSWNnR0FBWUFDSU9DZ3dJOGJfcnBnWVFnS3F4NVFF&key=AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4&alt=json returned \"The API server failed to successfully process the request. While this can be a transient error, it usually indicates that the request's input is invalid. Check the structure of the <code>commentThread</code> resource in the request body to ensure that it is valid.\">\n",
      "22 / 50\n",
      "Fetching comments for video HeMIZC2rkMo\n",
      "23 / 50\n",
      "Fetching comments for video lm_8IyKsseg\n",
      "24 / 50\n",
      "Fetching comments for video fvTCkaVISpo\n",
      "25 / 50\n",
      "Fetching comments for video 9ZgjTSsFB3U\n",
      "26 / 50\n",
      "Fetching comments for video 9yskPzCnEBo\n",
      "27 / 50\n",
      "Fetching comments for video CYcui7Q6llU\n",
      "28 / 50\n",
      "Fetching comments for video 8TlrXc3TYgs\n",
      "29 / 50\n",
      "Fetching comments for video rVVL3gTxlv0\n",
      "30 / 50\n",
      "Fetching comments for video RIphIqHEdxY\n",
      "31 / 50\n",
      "Fetching comments for video u65QuZT1ZJo\n",
      "32 / 50\n",
      "Fetching comments for video GmgAutwvDZI\n",
      "33 / 50\n",
      "Fetching comments for video RZojwiy3r_g\n",
      "34 / 50\n",
      "Fetching comments for video BWle_3grctY\n",
      "35 / 50\n",
      "Fetching comments for video tfoQcDRHYms\n",
      "36 / 50\n",
      "Fetching comments for video bMsiIN95GY8\n",
      "37 / 50\n",
      "Fetching comments for video mKTTqnLYU7w\n",
      "38 / 50\n",
      "Fetching comments for video bKKK3s90Vy8\n",
      "39 / 50\n",
      "Fetching comments for video H--dGk2Z6WE\n",
      "40 / 50\n",
      "Fetching comments for video ngC_xIO1KNU\n",
      "41 / 50\n",
      "Fetching comments for video 9g-bm0EmxlM\n",
      "42 / 50\n",
      "Fetching comments for video 0L952mpdBx8\n",
      "43 / 50\n",
      "Fetching comments for video r-vZYb5xIDg\n",
      "44 / 50\n",
      "Fetching comments for video x6VK9cBSrHU\n",
      "45 / 50\n",
      "Fetching comments for video 3ETMrpnVcbc\n",
      "46 / 50\n",
      "Fetching comments for video ctkW3V0Mh-k\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=ctkW3V0Mh-k&textFormat=plainText&maxResults=100&key=AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\">\n",
      "47 / 50\n",
      "Fetching comments for video fdNVfAWuLNg\n",
      "48 / 50\n",
      "Fetching comments for video 0okuAwqTHs0\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=0okuAwqTHs0&textFormat=plainText&maxResults=100&key=AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\">\n",
      "49 / 50\n",
      "Fetching comments for video l0EhXxrtmK0\n",
      "50 / 50\n",
      "Fetching comments for video TfmE_7tTKSI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search</th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgwuZ0IvcR2eBzmPwax4AaABAg</td>\n",
       "      <td>iPhone 4s was the perfect size.</td>\n",
       "      <td>Carlos Vega</td>\n",
       "      <td>2023-11-07T04:49:36Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgzguuMuaAx24szlaAp4AaABAg</td>\n",
       "      <td>I went from the iPhone 3GS to 4 to 4S to 5 to ...</td>\n",
       "      <td>user</td>\n",
       "      <td>2023-11-06T22:33:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgyGaqW4zXg9OvvN9014AaABAg</td>\n",
       "      <td>Beginning 0:01\\niPhone 0:02\\niPhone 3G 0:13\\ni...</td>\n",
       "      <td>iPhone 5s</td>\n",
       "      <td>2023-11-06T00:48:43Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgzbV3ptoU69pXWsJ-V4AaABAg</td>\n",
       "      <td>My evolution of owning an iPhone \\n3Gs\\n4s\\n5s...</td>\n",
       "      <td>Sunshine19</td>\n",
       "      <td>2023-10-29T22:29:27Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>Ugx7_-E4N4MVG3oN2q14AaABAg</td>\n",
       "      <td>Every iPhone: Our subtitles are revolations!\\n...</td>\n",
       "      <td>J-D Flash Studios { Discontinued }</td>\n",
       "      <td>2023-10-29T14:14:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45294</th>\n",
       "      <td>Macbook</td>\n",
       "      <td>TfmE_7tTKSI</td>\n",
       "      <td>UgwvI9fg7rhsJ1_eKBt4AaABAg</td>\n",
       "      <td>I would be here even if you were only unboxing...</td>\n",
       "      <td>Erik Marez</td>\n",
       "      <td>2023-06-14T20:20:26Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45295</th>\n",
       "      <td>Macbook</td>\n",
       "      <td>TfmE_7tTKSI</td>\n",
       "      <td>UgyVqyeZfNEOdamXUEJ4AaABAg</td>\n",
       "      <td>So lovely to be watching this on my brand new ...</td>\n",
       "      <td>Alfred</td>\n",
       "      <td>2023-06-14T20:19:00Z</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45296</th>\n",
       "      <td>Macbook</td>\n",
       "      <td>TfmE_7tTKSI</td>\n",
       "      <td>UgxXjTW9jDaZq5IIMRZ4AaABAg</td>\n",
       "      <td>How many of you guys are watching this video b...</td>\n",
       "      <td>visan florin mihai</td>\n",
       "      <td>2023-06-14T20:13:43Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45297</th>\n",
       "      <td>Macbook</td>\n",
       "      <td>TfmE_7tTKSI</td>\n",
       "      <td>Ugx6UA2ndDWQUP6JFfJ4AaABAg</td>\n",
       "      <td>You wouldn’t think 1 inch would make much of a...</td>\n",
       "      <td>MegaBeanHead</td>\n",
       "      <td>2023-06-14T20:13:29Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45298</th>\n",
       "      <td>Macbook</td>\n",
       "      <td>TfmE_7tTKSI</td>\n",
       "      <td>UgxiZLDCd4mnC9tT5JR4AaABAg</td>\n",
       "      <td>Never own a MacBook before. Just using an old ...</td>\n",
       "      <td>Dennis Marshall</td>\n",
       "      <td>2023-06-14T20:12:54Z</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40568 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Search     video_id                  comment_id  \\\n",
       "0       iPhone  pV0ud2B8WfQ  UgwuZ0IvcR2eBzmPwax4AaABAg   \n",
       "1       iPhone  pV0ud2B8WfQ  UgzguuMuaAx24szlaAp4AaABAg   \n",
       "2       iPhone  pV0ud2B8WfQ  UgyGaqW4zXg9OvvN9014AaABAg   \n",
       "3       iPhone  pV0ud2B8WfQ  UgzbV3ptoU69pXWsJ-V4AaABAg   \n",
       "4       iPhone  pV0ud2B8WfQ  Ugx7_-E4N4MVG3oN2q14AaABAg   \n",
       "...        ...          ...                         ...   \n",
       "45294  Macbook  TfmE_7tTKSI  UgwvI9fg7rhsJ1_eKBt4AaABAg   \n",
       "45295  Macbook  TfmE_7tTKSI  UgyVqyeZfNEOdamXUEJ4AaABAg   \n",
       "45296  Macbook  TfmE_7tTKSI  UgxXjTW9jDaZq5IIMRZ4AaABAg   \n",
       "45297  Macbook  TfmE_7tTKSI  Ugx6UA2ndDWQUP6JFfJ4AaABAg   \n",
       "45298  Macbook  TfmE_7tTKSI  UgxiZLDCd4mnC9tT5JR4AaABAg   \n",
       "\n",
       "                                                    text  \\\n",
       "0                        iPhone 4s was the perfect size.   \n",
       "1      I went from the iPhone 3GS to 4 to 4S to 5 to ...   \n",
       "2      Beginning 0:01\\niPhone 0:02\\niPhone 3G 0:13\\ni...   \n",
       "3      My evolution of owning an iPhone \\n3Gs\\n4s\\n5s...   \n",
       "4      Every iPhone: Our subtitles are revolations!\\n...   \n",
       "...                                                  ...   \n",
       "45294  I would be here even if you were only unboxing...   \n",
       "45295  So lovely to be watching this on my brand new ...   \n",
       "45296  How many of you guys are watching this video b...   \n",
       "45297  You wouldn’t think 1 inch would make much of a...   \n",
       "45298  Never own a MacBook before. Just using an old ...   \n",
       "\n",
       "                                   author                  date like_count  \\\n",
       "0                             Carlos Vega  2023-11-07T04:49:36Z          0   \n",
       "1                                    user  2023-11-06T22:33:16Z          0   \n",
       "2                               iPhone 5s  2023-11-06T00:48:43Z          1   \n",
       "3                              Sunshine19  2023-10-29T22:29:27Z          0   \n",
       "4      J-D Flash Studios { Discontinued }  2023-10-29T14:14:16Z          0   \n",
       "...                                   ...                   ...        ...   \n",
       "45294                          Erik Marez  2023-06-14T20:20:26Z          1   \n",
       "45295                              Alfred  2023-06-14T20:19:00Z         15   \n",
       "45296                  visan florin mihai  2023-06-14T20:13:43Z          0   \n",
       "45297                        MegaBeanHead  2023-06-14T20:13:29Z          1   \n",
       "45298                     Dennis Marshall  2023-06-14T20:12:54Z          0   \n",
       "\n",
       "      reply_count  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "45294           0  \n",
       "45295           0  \n",
       "45296           0  \n",
       "45297           0  \n",
       "45298           3  \n",
       "\n",
       "[40568 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules from the Google API client library\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Replace 'api_key' with your actual YouTube Data API key\n",
    "api_key = 'AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Function to search for videos based on a query and retrieve video IDs\n",
    "def search_videos(youtube, query, max_results):\n",
    "    # Execute the search query and extract video IDs\n",
    "    search_response = youtube.search().list(\n",
    "        q=query,\n",
    "        part='id',\n",
    "        maxResults=max_results,\n",
    "        type='video'\n",
    "    ).execute()\n",
    "    video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "    return video_ids\n",
    "\n",
    "# Function to retrieve comments for a given video ID\n",
    "def get_comments(youtube, video_id):\n",
    "    comments_data = []\n",
    "    try:\n",
    "        # Iterate through pages of comments using pagination\n",
    "        page_token = None\n",
    "        while True:\n",
    "            response = youtube.commentThreads().list(\n",
    "                part='snippet,replies',\n",
    "                videoId=video_id,\n",
    "                textFormat='plainText',\n",
    "                maxResults=100,\n",
    "                pageToken=page_token\n",
    "            ).execute()\n",
    "\n",
    "            # Extract relevant information from each comment\n",
    "            for item in response['items']:\n",
    "                top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "                comments_data.append({\n",
    "                    'video_id': video_id,\n",
    "                    'comment_id': item['id'],\n",
    "                    'text': top_comment['textDisplay'],\n",
    "                    'author': top_comment['authorDisplayName'],\n",
    "                    'date': top_comment['publishedAt'],\n",
    "                    'like_count': top_comment['likeCount'],\n",
    "                    'reply_count': item['snippet']['totalReplyCount']\n",
    "                })\n",
    "\n",
    "            # Check for the presence of additional pages of comments\n",
    "            page_token = response.get('nextPageToken')\n",
    "            if not page_token:\n",
    "                break\n",
    "\n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "    return comments_data\n",
    "\n",
    "# Search for videos with the keyword \"Macbook\" and retrieve video IDs\n",
    "video_ids = search_videos(youtube, \"Macbook\", 100)\n",
    "\n",
    "# Collect comments from each video and filter for those containing \"Macbook\"\n",
    "all_comments = []\n",
    "for video_id in range(len(video_ids)):\n",
    "    print(str(video_id+1) + \" / \" + str(len(video_ids)))\n",
    "    print(f'Fetching comments for video {video_ids[video_id]}')\n",
    "    comments = get_comments(youtube, video_ids[video_id])\n",
    "\n",
    "    # Filter comments containing the keyword \"Macbook\"\n",
    "    temp_df = pd.DataFrame(all_comments)\n",
    "    temp_df = temp_df[temp_df['text'].str.contains(\"Macbook\", case=False)]\n",
    "    temp_df = temp_df.dropna(subset=['text'])\n",
    "    temp_df['Search'] = 'Macbook'\n",
    "    \n",
    "    # Append the filtered comments to the overall DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    df = df.dropna(subset=['text']).drop_duplicates(subset=['text'])\n",
    "\n",
    "    # Save the DataFrame to a CSV file after each iteration\n",
    "    df.to_csv('youtube_comments.csv', index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique Apple product\n",
    "df.Search.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 50\n",
      "Fetching comments for video Nvb_Kta7v6U\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=Nvb_Kta7v6U&textFormat=plainText&maxResults=100&key=AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\">\n",
      "2 / 50\n",
      "Fetching comments for video oNCs4C2SMjo\n",
      "3 / 50\n",
      "Fetching comments for video CLOOLOdg5Jw\n",
      "4 / 50\n",
      "Fetching comments for video MF5odeotkKA\n",
      "5 / 50\n",
      "Fetching comments for video aPN13ULL0k4\n",
      "6 / 50\n",
      "Fetching comments for video _mOqJyNHkhI\n",
      "7 / 50\n",
      "Fetching comments for video 7LaR7meroVI\n",
      "8 / 50\n",
      "Fetching comments for video 6J5o4J-Ttp8\n",
      "9 / 50\n",
      "Fetching comments for video J6hCaO7n35o\n",
      "10 / 50\n",
      "Fetching comments for video JCLsnO2WOEQ\n",
      "11 / 50\n",
      "Fetching comments for video FcF0F4lYi_U\n",
      "12 / 50\n",
      "Fetching comments for video 6kZWFmuSDys\n",
      "13 / 50\n",
      "Fetching comments for video Ceqabjjgh8o\n",
      "14 / 50\n",
      "Fetching comments for video 67wEGmtrtiM\n",
      "15 / 50\n",
      "Fetching comments for video liJZ_K83TrU\n",
      "16 / 50\n",
      "Fetching comments for video Ek2nUYzlLlo\n",
      "17 / 50\n",
      "Fetching comments for video JCe0LaHpz1I\n",
      "18 / 50\n",
      "Fetching comments for video l4c4QmyqTyA\n",
      "19 / 50\n",
      "Fetching comments for video 8AJATv6mf7U\n",
      "20 / 50\n",
      "Fetching comments for video Ps2gRm2E3DE\n",
      "21 / 50\n",
      "Fetching comments for video gZ7zpu2qZ0E\n",
      "22 / 50\n",
      "Fetching comments for video cgAuJt4cGeo\n",
      "23 / 50\n",
      "Fetching comments for video 2QT3p-yEIsA\n",
      "24 / 50\n",
      "Fetching comments for video WErwDAy-Pbo\n",
      "25 / 50\n",
      "Fetching comments for video AFr7vvQfvO8\n",
      "26 / 50\n",
      "Fetching comments for video f96ccsEKs_M\n",
      "27 / 50\n",
      "Fetching comments for video e4gBAOB3czA\n",
      "28 / 50\n",
      "Fetching comments for video JbDBzYxgKYU\n",
      "29 / 50\n",
      "Fetching comments for video 1aFuFrQyhdE\n",
      "30 / 50\n",
      "Fetching comments for video BgCdbEe36DU\n",
      "An error occurred: <HttpError 400 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=BgCdbEe36DU&textFormat=plainText&maxResults=100&pageToken=Z2V0X25ld2VzdF9maXJzdC0tQ2dnSWdBUVZGN2ZST0JJRkNJa2dHQUFTQlFpSElCZ0FFZ1VJaUNBWUFCSUZDSjBnR0FFWUFDSU5DZ3NJc2VMRnFBWVF1Tl9hVnc%3D&key=AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4&alt=json returned \"The API server failed to successfully process the request. While this can be a transient error, it usually indicates that the request's input is invalid. Check the structure of the <code>commentThread</code> resource in the request body to ensure that it is valid.\">\n",
      "31 / 50\n",
      "Fetching comments for video B0WVGsWRRkQ\n",
      "32 / 50\n",
      "Fetching comments for video rNwVgqi4ji0\n",
      "33 / 50\n",
      "Fetching comments for video -SdbX2Sdx0E\n",
      "34 / 50\n",
      "Fetching comments for video -LOZkf64AAc\n",
      "35 / 50\n",
      "Fetching comments for video fDYEhgHgvLE\n",
      "36 / 50\n",
      "Fetching comments for video W_yS1YaftoU\n",
      "37 / 50\n",
      "Fetching comments for video UhRyC6VGFfk\n",
      "38 / 50\n",
      "Fetching comments for video 5gkiXZ_DjOw\n",
      "39 / 50\n",
      "Fetching comments for video Ax_uIV58L54\n",
      "40 / 50\n",
      "Fetching comments for video Z5HlB8fErEc\n",
      "41 / 50\n",
      "Fetching comments for video 9qBucp5JQ14\n",
      "42 / 50\n",
      "Fetching comments for video qgL87pISJCQ\n",
      "43 / 50\n",
      "Fetching comments for video 4iJ7MIVqQ2c\n",
      "44 / 50\n",
      "Fetching comments for video Pz-cnlNVVEI\n",
      "45 / 50\n",
      "Fetching comments for video ygwbBd9cxuI\n",
      "46 / 50\n",
      "Fetching comments for video pLaexdG9Rh4\n",
      "47 / 50\n",
      "Fetching comments for video ZgCGJYgAdbc\n",
      "48 / 50\n",
      "Fetching comments for video HjEqOWjTkHE\n",
      "49 / 50\n",
      "Fetching comments for video Zn-HSCZURR0\n",
      "50 / 50\n",
      "Fetching comments for video bFaukZe0uSk\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search</th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgwuZ0IvcR2eBzmPwax4AaABAg</td>\n",
       "      <td>iPhone 4s was the perfect size.</td>\n",
       "      <td>Carlos Vega</td>\n",
       "      <td>2023-11-07T04:49:36Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgzguuMuaAx24szlaAp4AaABAg</td>\n",
       "      <td>I went from the iPhone 3GS to 4 to 4S to 5 to ...</td>\n",
       "      <td>user</td>\n",
       "      <td>2023-11-06T22:33:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgyGaqW4zXg9OvvN9014AaABAg</td>\n",
       "      <td>Beginning 0:01\\niPhone 0:02\\niPhone 3G 0:13\\ni...</td>\n",
       "      <td>iPhone 5s</td>\n",
       "      <td>2023-11-06T00:48:43Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>UgzbV3ptoU69pXWsJ-V4AaABAg</td>\n",
       "      <td>My evolution of owning an iPhone \\n3Gs\\n4s\\n5s...</td>\n",
       "      <td>Sunshine19</td>\n",
       "      <td>2023-10-29T22:29:27Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>pV0ud2B8WfQ</td>\n",
       "      <td>Ugx7_-E4N4MVG3oN2q14AaABAg</td>\n",
       "      <td>Every iPhone: Our subtitles are revolations!\\n...</td>\n",
       "      <td>J-D Flash Studios { Discontinued }</td>\n",
       "      <td>2023-10-29T14:14:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46120</th>\n",
       "      <td>Apple Watch</td>\n",
       "      <td>bFaukZe0uSk</td>\n",
       "      <td>UgzxwmoinS3v_MgBO_N4AaABAg</td>\n",
       "      <td>Many of us are comfortable with Android phones...</td>\n",
       "      <td>Anish Thomas</td>\n",
       "      <td>2022-09-14T14:57:52Z</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46121</th>\n",
       "      <td>Apple Watch</td>\n",
       "      <td>bFaukZe0uSk</td>\n",
       "      <td>UgyjJEN7VwJ-6IB19Qd4AaABAg</td>\n",
       "      <td>I went with the Apple Watch Ultra mainly for t...</td>\n",
       "      <td>BP</td>\n",
       "      <td>2022-09-14T14:20:49Z</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46122</th>\n",
       "      <td>Apple Watch</td>\n",
       "      <td>bFaukZe0uSk</td>\n",
       "      <td>Ugzc_FkNY7JXKz6nmPF4AaABAg</td>\n",
       "      <td>Just buy last year Apple Watch Series 7. Skip ...</td>\n",
       "      <td>Csaba Teplan</td>\n",
       "      <td>2022-09-14T14:19:26Z</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46123</th>\n",
       "      <td>Apple Watch</td>\n",
       "      <td>bFaukZe0uSk</td>\n",
       "      <td>Ugx6ruHzlpjb6UEBeGB4AaABAg</td>\n",
       "      <td>Does de Apple Watch Ultra will be compatible w...</td>\n",
       "      <td>antonio caballero</td>\n",
       "      <td>2022-09-14T14:15:03Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46124</th>\n",
       "      <td>Apple Watch</td>\n",
       "      <td>bFaukZe0uSk</td>\n",
       "      <td>UgwbNkzJnwK5-xvrkKF4AaABAg</td>\n",
       "      <td>I'm glad I got the SE 1, the SE 2 doesn't seem...</td>\n",
       "      <td>Apple Pi</td>\n",
       "      <td>2022-09-14T14:14:03Z</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43356 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Search     video_id                  comment_id  \\\n",
       "0           iPhone  pV0ud2B8WfQ  UgwuZ0IvcR2eBzmPwax4AaABAg   \n",
       "1           iPhone  pV0ud2B8WfQ  UgzguuMuaAx24szlaAp4AaABAg   \n",
       "2           iPhone  pV0ud2B8WfQ  UgyGaqW4zXg9OvvN9014AaABAg   \n",
       "3           iPhone  pV0ud2B8WfQ  UgzbV3ptoU69pXWsJ-V4AaABAg   \n",
       "4           iPhone  pV0ud2B8WfQ  Ugx7_-E4N4MVG3oN2q14AaABAg   \n",
       "...            ...          ...                         ...   \n",
       "46120  Apple Watch  bFaukZe0uSk  UgzxwmoinS3v_MgBO_N4AaABAg   \n",
       "46121  Apple Watch  bFaukZe0uSk  UgyjJEN7VwJ-6IB19Qd4AaABAg   \n",
       "46122  Apple Watch  bFaukZe0uSk  Ugzc_FkNY7JXKz6nmPF4AaABAg   \n",
       "46123  Apple Watch  bFaukZe0uSk  Ugx6ruHzlpjb6UEBeGB4AaABAg   \n",
       "46124  Apple Watch  bFaukZe0uSk  UgwbNkzJnwK5-xvrkKF4AaABAg   \n",
       "\n",
       "                                                    text  \\\n",
       "0                        iPhone 4s was the perfect size.   \n",
       "1      I went from the iPhone 3GS to 4 to 4S to 5 to ...   \n",
       "2      Beginning 0:01\\niPhone 0:02\\niPhone 3G 0:13\\ni...   \n",
       "3      My evolution of owning an iPhone \\n3Gs\\n4s\\n5s...   \n",
       "4      Every iPhone: Our subtitles are revolations!\\n...   \n",
       "...                                                  ...   \n",
       "46120  Many of us are comfortable with Android phones...   \n",
       "46121  I went with the Apple Watch Ultra mainly for t...   \n",
       "46122  Just buy last year Apple Watch Series 7. Skip ...   \n",
       "46123  Does de Apple Watch Ultra will be compatible w...   \n",
       "46124  I'm glad I got the SE 1, the SE 2 doesn't seem...   \n",
       "\n",
       "                                   author                  date like_count  \\\n",
       "0                             Carlos Vega  2023-11-07T04:49:36Z          0   \n",
       "1                                    user  2023-11-06T22:33:16Z          0   \n",
       "2                               iPhone 5s  2023-11-06T00:48:43Z          1   \n",
       "3                              Sunshine19  2023-10-29T22:29:27Z          0   \n",
       "4      J-D Flash Studios { Discontinued }  2023-10-29T14:14:16Z          0   \n",
       "...                                   ...                   ...        ...   \n",
       "46120                        Anish Thomas  2022-09-14T14:57:52Z         10   \n",
       "46121                                  BP  2022-09-14T14:20:49Z         84   \n",
       "46122                        Csaba Teplan  2022-09-14T14:19:26Z          0   \n",
       "46123                   antonio caballero  2022-09-14T14:15:03Z          0   \n",
       "46124                            Apple Pi  2022-09-14T14:14:03Z         17   \n",
       "\n",
       "      reply_count  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "46120           0  \n",
       "46121           7  \n",
       "46122           3  \n",
       "46123           1  \n",
       "46124           3  \n",
       "\n",
       "[43356 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules from the Google API client library\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Replace 'api_key' with your actual YouTube Data API key\n",
    "api_key = 'AIzaSyCay1rVJ0CbxR3Bk1uVcVKScvTSYlsKcE4'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Function to search for videos based on a query and retrieve video IDs\n",
    "def search_videos(youtube, query, max_results):\n",
    "    # Execute the search query and extract video IDs\n",
    "    search_response = youtube.search().list(\n",
    "        q=query,\n",
    "        part='id',\n",
    "        maxResults=max_results,\n",
    "        type='video'\n",
    "    ).execute()\n",
    "    video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "    return video_ids\n",
    "\n",
    "# Function to retrieve comments for a given video ID\n",
    "def get_comments(youtube, video_id):\n",
    "    comments_data = []\n",
    "    try:\n",
    "        # Iterate through pages of comments using pagination\n",
    "        page_token = None\n",
    "        while True:\n",
    "            response = youtube.commentThreads().list(\n",
    "                part='snippet,replies',\n",
    "                videoId=video_id,\n",
    "                textFormat='plainText',\n",
    "                maxResults=100,\n",
    "                pageToken=page_token\n",
    "            ).execute()\n",
    "\n",
    "            # Extract relevant information from each comment\n",
    "            for item in response['items']:\n",
    "                top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "                comments_data.append({\n",
    "                    'video_id': video_id,\n",
    "                    'comment_id': item['id'],\n",
    "                    'text': top_comment['textDisplay'],\n",
    "                    'author': top_comment['authorDisplayName'],\n",
    "                    'date': top_comment['publishedAt'],\n",
    "                    'like_count': top_comment['likeCount'],\n",
    "                    'reply_count': item['snippet']['totalReplyCount']\n",
    "                })\n",
    "\n",
    "            # Check for the presence of additional pages of comments\n",
    "            page_token = response.get('nextPageToken')\n",
    "            if not page_token:\n",
    "                break\n",
    "\n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "    return comments_data\n",
    "\n",
    "# Search for videos with the keyword \"Apple Watch\" and retrieve video IDs\n",
    "video_ids = search_videos(youtube, \"Apple Watch\", 100)\n",
    "\n",
    "# Collect comments from each video and filter for those containing \"Apple Watch\"\n",
    "all_comments = []\n",
    "for video_id in range(len(video_ids)):\n",
    "    print(str(video_id+1) + \" / \" + str(len(video_ids)))\n",
    "    print(f'Fetching comments for video {video_ids[video_id]}')\n",
    "    comments = get_comments(youtube, video_ids[video_id])\n",
    "\n",
    "    # Filter comments containing the keyword \"Apple Watch\"\n",
    "    temp_df = pd.DataFrame(all_comments)\n",
    "    try:\n",
    "        temp_df = temp_df[temp_df['text'].str.contains(\"Apple Watch\", case=False)]\n",
    "    except:\n",
    "        continue\n",
    "    temp_df = temp_df.dropna(subset=['text'])\n",
    "    temp_df['Search'] = 'Apple Watch'\n",
    "    \n",
    "    # Append the filtered comments to the overall DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    df = df.dropna(subset=['text']).drop_duplicates(subset=['text'])\n",
    "\n",
    "    # Save the DataFrame to a CSV file after each iteration\n",
    "    df.to_csv('youtube_comments.csv', index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad           16960\n",
       "iPhone         15984\n",
       "Macbook         4779\n",
       "AirPods         2845\n",
       "Apple Watch     2788\n",
       "Name: Search, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each unique Apple product\n",
    "df.Search.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
