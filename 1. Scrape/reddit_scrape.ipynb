{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975edfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478823ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_Body</th>\n",
       "      <th>Author</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Awards</th>\n",
       "      <th>Date</th>\n",
       "      <th>Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happened to my sister on her iPhone 14 Pro Max...</td>\n",
       "      <td>Yimyorn</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-28 15:12:29</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The amount of bad iPhone 15 models I’m seeing ...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-28 15:19:28</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Im getting a 15 pro tomorrow. Im getting incre...</td>\n",
       "      <td>DiffuseSpy</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-28 16:31:27</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>That’s an explosion risk. The battery is faili...</td>\n",
       "      <td>revmachine21</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-29 03:57:05</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anyone else get that feeling we’re about to st...</td>\n",
       "      <td>wintrymixxx</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-28 14:36:19</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>Real talk time: iOS and Android are essentiall...</td>\n",
       "      <td>LucidLethargy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-17 07:32:47</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>Also, please release an iPhone Ultra with an e...</td>\n",
       "      <td>Ftpini</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-16 16:35:26</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>Please kill the iPhone mini.</td>\n",
       "      <td>radfordra1</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-16 18:17:53</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>Please kill the iPhone Mini</td>\n",
       "      <td>PartyCrab9</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-17 00:41:17</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>&gt; Or Apple could bring it back in 2024 as a ne...</td>\n",
       "      <td>coreyonfire</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-16 16:12:04</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3654 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Comment_Body         Author  \\\n",
       "0     Happened to my sister on her iPhone 14 Pro Max...        Yimyorn   \n",
       "1     The amount of bad iPhone 15 models I’m seeing ...      [deleted]   \n",
       "2     Im getting a 15 pro tomorrow. Im getting incre...     DiffuseSpy   \n",
       "3     That’s an explosion risk. The battery is faili...   revmachine21   \n",
       "4     anyone else get that feeling we’re about to st...    wintrymixxx   \n",
       "...                                                 ...            ...   \n",
       "3657  Real talk time: iOS and Android are essentiall...  LucidLethargy   \n",
       "3658  Also, please release an iPhone Ultra with an e...         Ftpini   \n",
       "3659                       Please kill the iPhone mini.     radfordra1   \n",
       "3660                        Please kill the iPhone Mini     PartyCrab9   \n",
       "3661  > Or Apple could bring it back in 2024 as a ne...    coreyonfire   \n",
       "\n",
       "      Upvotes  Awards                Date  Search  \n",
       "0          43       0 2023-09-28 15:12:29  iPhone  \n",
       "1         274       0 2023-09-28 15:19:28  iPhone  \n",
       "2          10       0 2023-09-28 16:31:27  iPhone  \n",
       "3           6       0 2023-09-29 03:57:05  iPhone  \n",
       "4          35       0 2023-09-28 14:36:19  iPhone  \n",
       "...       ...     ...                 ...     ...  \n",
       "3657        1       0 2022-03-17 07:32:47  iPhone  \n",
       "3658       -5       0 2022-03-16 16:35:26  iPhone  \n",
       "3659       -7       0 2022-03-16 18:17:53  iPhone  \n",
       "3660       -5       0 2022-03-17 00:41:17  iPhone  \n",
       "3661       -9       0 2022-03-16 16:12:04  iPhone  \n",
       "\n",
       "[3654 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This script extracts comments from Reddit using the praw library, filters, and saves them in a CSV file.\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "SECRET = \"fDTjgQd2sS6gmVrqm7IcPPhp05NHXg\"\n",
    "APP_ID = \"KGv2MMUcdlqidiWTIP4YPA\"\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "        client_id=APP_ID,\n",
    "        client_secret=SECRET,\n",
    "        user_agent=\"Comment Extraction\")\n",
    "\n",
    "search_query = \"iPhone\"\n",
    "max_comments = 1000\n",
    "\n",
    "comment_bodies = []\n",
    "comment_authors = []\n",
    "comment_upvotes = []\n",
    "comment_awards = []\n",
    "comment_dates = []\n",
    "\n",
    "start_date = datetime(2022, 1, 1)\n",
    "end_date = datetime(2023, 11, 2)\n",
    "\n",
    "for submission in reddit.subreddit(\"all\").search(search_query, limit=max_comments):\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    for comment in submission.comments:\n",
    "        if comment.is_root:\n",
    "            comment_date = datetime.utcfromtimestamp(comment.created_utc)\n",
    "            if start_date <= comment_date <= end_date:\n",
    "                comment_bodies.append(comment.body)\n",
    "                comment_authors.append(comment.author.name if comment.author else \"[deleted]\")\n",
    "                comment_upvotes.append(comment.score)\n",
    "                comment_awards.append(comment.total_awards_received)\n",
    "                comment_dates.append(comment_date)\n",
    "\n",
    "data = {\n",
    "    \"Comment_Body\": comment_bodies,\n",
    "    \"Author\": comment_authors,\n",
    "    \"Upvotes\": comment_upvotes,\n",
    "    \"Awards\": comment_awards,\n",
    "    \"Date\": comment_dates,\n",
    "}\n",
    "\n",
    "temp_df = pd.DataFrame(data)\n",
    "\n",
    "temp_df = temp_df[temp_df['Author'] != 'AutoModerator']\n",
    "temp_df = temp_df[temp_df['Comment_Body'] != '[deleted]']\n",
    "temp_df = temp_df[~temp_df['Comment_Body'].str.contains(r'\\[Banned for overrating\\]', case=False)]\n",
    "temp_df = temp_df[~temp_df['Comment_Body'].str.contains(r'\\br/\\w+', case=False)]\n",
    "temp_df = temp_df[temp_df['Comment_Body'].str.contains(\"iPhone\", case=False)]\n",
    "temp_df = temp_df.dropna(subset=['Comment_Body'])\n",
    "\n",
    "temp_df['Search'] = 'iPhone'\n",
    "\n",
    "df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "df = df.dropna(subset=['Comment_Body']).drop_duplicates(subset=['Comment_Body'])\n",
    "df.to_csv('reddit_comments.csv', index=False)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceffe3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_Body</th>\n",
       "      <th>Author</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Awards</th>\n",
       "      <th>Date</th>\n",
       "      <th>Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Funny how Argentina isn't even on the list bec...</td>\n",
       "      <td>Yearlaren</td>\n",
       "      <td>3962</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 15:32:23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And just to add salt to the wound, iPhone in P...</td>\n",
       "      <td>pole_verme</td>\n",
       "      <td>1813</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 13:38:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I read a article saying that it was cheaper to...</td>\n",
       "      <td>_karma_bitch</td>\n",
       "      <td>1649</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 13:36:33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As a person that lived in the third world for ...</td>\n",
       "      <td>Momovsky</td>\n",
       "      <td>2851</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 12:40:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norwegian here. Number seems fairly accurate, ...</td>\n",
       "      <td>soffagrisen2</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 14:55:45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8816</th>\n",
       "      <td>I got my wife a new MacBook Air M2 and she kee...</td>\n",
       "      <td>LazaroFilm</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-14 00:23:18</td>\n",
       "      <td>Macbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8817</th>\n",
       "      <td>Just upgraded from my 2015 MacBook Pro. Repres...</td>\n",
       "      <td>kinetokkin</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-14 12:31:55</td>\n",
       "      <td>Macbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8818</th>\n",
       "      <td>Me 2!! I had a 2012 retina before my new M1 Pr...</td>\n",
       "      <td>Recognition_Round</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-14 12:44:01</td>\n",
       "      <td>Macbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8819</th>\n",
       "      <td>Same here! 2014 15 inch MacBook Pro -&gt; M1 16Gb...</td>\n",
       "      <td>RandomMishaps</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-14 13:09:51</td>\n",
       "      <td>Macbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8820</th>\n",
       "      <td>Im still using a 2015 macbook pro and i hate it</td>\n",
       "      <td>snacks4ever</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-23 07:13:48</td>\n",
       "      <td>Macbook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8818 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Comment_Body             Author  \\\n",
       "0     Funny how Argentina isn't even on the list bec...          Yearlaren   \n",
       "1     And just to add salt to the wound, iPhone in P...         pole_verme   \n",
       "2     I read a article saying that it was cheaper to...       _karma_bitch   \n",
       "3     As a person that lived in the third world for ...           Momovsky   \n",
       "4     Norwegian here. Number seems fairly accurate, ...       soffagrisen2   \n",
       "...                                                 ...                ...   \n",
       "8816  I got my wife a new MacBook Air M2 and she kee...         LazaroFilm   \n",
       "8817  Just upgraded from my 2015 MacBook Pro. Repres...         kinetokkin   \n",
       "8818  Me 2!! I had a 2012 retina before my new M1 Pr...  Recognition_Round   \n",
       "8819  Same here! 2014 15 inch MacBook Pro -> M1 16Gb...      RandomMishaps   \n",
       "8820    Im still using a 2015 macbook pro and i hate it        snacks4ever   \n",
       "\n",
       "      Upvotes  Awards                Date   Search  \n",
       "0        3962       0 2022-09-12 15:32:23      NaN  \n",
       "1        1813       0 2022-09-12 13:38:00      NaN  \n",
       "2        1649       0 2022-09-12 13:36:33      NaN  \n",
       "3        2851       0 2022-09-12 12:40:50      NaN  \n",
       "4         181       0 2022-09-12 14:55:45      NaN  \n",
       "...       ...     ...                 ...      ...  \n",
       "8816        1       0 2023-01-14 00:23:18  Macbook  \n",
       "8817        1       0 2023-01-14 12:31:55  Macbook  \n",
       "8818        1       0 2023-01-14 12:44:01  Macbook  \n",
       "8819        1       0 2023-01-14 13:09:51  Macbook  \n",
       "8820        2       0 2023-10-23 07:13:48  Macbook  \n",
       "\n",
       "[8818 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Reddit API credentials\n",
    "SECRET = \"fDTjgQd2sS6gmVrqm7IcPPhp05NHXg\"\n",
    "APP_ID = \"KGv2MMUcdlqidiWTIP4YPA\"\n",
    "\n",
    "# Authenticate with Reddit using praw\n",
    "reddit = praw.Reddit(\n",
    "        client_id=APP_ID,\n",
    "        client_secret=SECRET,\n",
    "        user_agent=\"Comment Extraction\")\n",
    "\n",
    "# Set search parameters\n",
    "search_query = \"Macbook\"\n",
    "max_comments = 1000\n",
    "\n",
    "# Initialize lists to store comment information\n",
    "comment_bodies = []\n",
    "comment_authors = []\n",
    "comment_upvotes = []\n",
    "comment_awards = []\n",
    "comment_dates = []\n",
    "\n",
    "# Set date range for comment extraction\n",
    "start_date = datetime(2022, 1, 1)\n",
    "end_date = datetime(2023, 11, 2)\n",
    "\n",
    "# Iterate through Reddit submissions containing the search query\n",
    "for submission in reddit.subreddit(\"all\").search(search_query, limit=max_comments):\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    for comment in submission.comments:\n",
    "        # Check if the comment is a root comment (not a reply)\n",
    "        if comment.is_root:\n",
    "            comment_date = datetime.utcfromtimestamp(comment.created_utc)\n",
    "            # Check if the comment is within the specified date range\n",
    "            if start_date <= comment_date <= end_date:\n",
    "                # Append relevant comment information to the lists\n",
    "                comment_bodies.append(comment.body)\n",
    "                comment_authors.append(comment.author.name if comment.author else \"[deleted]\")\n",
    "                comment_upvotes.append(comment.score)\n",
    "                comment_awards.append(comment.total_awards_received)\n",
    "                comment_dates.append(comment_date)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    \"Comment_Body\": comment_bodies,\n",
    "    \"Author\": comment_authors,\n",
    "    \"Upvotes\": comment_upvotes,\n",
    "    \"Awards\": comment_awards,\n",
    "    \"Date\": comment_dates,\n",
    "}\n",
    "\n",
    "temp_df = pd.DataFrame(data)\n",
    "\n",
    "# Data cleaning and filtering\n",
    "temp_df = temp_df[temp_df['Author'] != 'AutoModerator']\n",
    "temp_df = temp_df[temp_df['Comment_Body'] != '[deleted]']\n",
    "temp_df = temp_df[~temp_df['Comment_Body'].str.contains(r'\\[Banned for overrating\\]', case=False)]\n",
    "temp_df = temp_df[~temp_df['Comment_Body'].str.contains(r'\\br/\\w+', case=False)]\n",
    "temp_df = temp_df[temp_df['Comment_Body'].str.contains(\"Macbook\", case=False)]\n",
    "temp_df = temp_df.dropna(subset=['Comment_Body'])\n",
    "\n",
    "# Add a column indicating the search term\n",
    "temp_df['Search'] = 'Macbook'\n",
    "\n",
    "# Concatenate the temporary DataFrame with the main DataFrame\n",
    "df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "# Drop duplicate comments and save the final DataFrame to a CSV file\n",
    "df = df.dropna(subset=['Comment_Body']).drop_duplicates(subset=['Comment_Body'])\n",
    "df.to_csv('reddit_comments.csv', index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68d34589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_Body</th>\n",
       "      <th>Author</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Awards</th>\n",
       "      <th>Date</th>\n",
       "      <th>Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Funny how Argentina isn't even on the list bec...</td>\n",
       "      <td>Yearlaren</td>\n",
       "      <td>3962</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 15:32:23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And just to add salt to the wound, iPhone in P...</td>\n",
       "      <td>pole_verme</td>\n",
       "      <td>1813</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 13:38:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I read a article saying that it was cheaper to...</td>\n",
       "      <td>_karma_bitch</td>\n",
       "      <td>1649</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 13:36:33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As a person that lived in the third world for ...</td>\n",
       "      <td>Momovsky</td>\n",
       "      <td>2851</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 12:40:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norwegian here. Number seems fairly accurate, ...</td>\n",
       "      <td>soffagrisen2</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 14:55:45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12198</th>\n",
       "      <td>What the hell? I’m using the iPad app…</td>\n",
       "      <td>Samness45</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-09 11:14:13</td>\n",
       "      <td>iPad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12199</th>\n",
       "      <td>Omg an iPad app??? No more blocked images when...</td>\n",
       "      <td>SlackLifesentence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-09 14:02:33</td>\n",
       "      <td>iPad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12200</th>\n",
       "      <td>As amazing as the iPhone app is, the iPad app ...</td>\n",
       "      <td>__BIOHAZARD___</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-09 14:15:54</td>\n",
       "      <td>iPad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12201</th>\n",
       "      <td>There was me thinking this was the iPad app. I...</td>\n",
       "      <td>Beena22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-09 19:24:40</td>\n",
       "      <td>iPad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12202</th>\n",
       "      <td>Is the ipad app really that bad?</td>\n",
       "      <td>milesbeats</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-09 22:08:45</td>\n",
       "      <td>iPad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comment_Body             Author  \\\n",
       "0      Funny how Argentina isn't even on the list bec...          Yearlaren   \n",
       "1      And just to add salt to the wound, iPhone in P...         pole_verme   \n",
       "2      I read a article saying that it was cheaper to...       _karma_bitch   \n",
       "3      As a person that lived in the third world for ...           Momovsky   \n",
       "4      Norwegian here. Number seems fairly accurate, ...       soffagrisen2   \n",
       "...                                                  ...                ...   \n",
       "12198             What the hell? I’m using the iPad app…          Samness45   \n",
       "12199  Omg an iPad app??? No more blocked images when...  SlackLifesentence   \n",
       "12200  As amazing as the iPhone app is, the iPad app ...     __BIOHAZARD___   \n",
       "12201  There was me thinking this was the iPad app. I...            Beena22   \n",
       "12202                   Is the ipad app really that bad?         milesbeats   \n",
       "\n",
       "       Upvotes  Awards                Date Search  \n",
       "0         3962       0 2022-09-12 15:32:23    NaN  \n",
       "1         1813       0 2022-09-12 13:38:00    NaN  \n",
       "2         1649       0 2022-09-12 13:36:33    NaN  \n",
       "3         2851       0 2022-09-12 12:40:50    NaN  \n",
       "4          181       0 2022-09-12 14:55:45    NaN  \n",
       "...        ...     ...                 ...    ...  \n",
       "12198       -6       0 2022-09-09 11:14:13   iPad  \n",
       "12199        1       0 2022-09-09 14:02:33   iPad  \n",
       "12200        1       0 2022-09-09 14:15:54   iPad  \n",
       "12201        1       0 2022-09-09 19:24:40   iPad  \n",
       "12202        1       0 2022-09-09 22:08:45   iPad  \n",
       "\n",
       "[12200 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Reddit API credentials\n",
    "SECRET = \"fDTjgQd2sS6gmVrqm7IcPPhp05NHXg\"\n",
    "APP_ID = \"KGv2MMUcdlqidiWTIP4YPA\"\n",
    "\n",
    "# Authenticate with Reddit using praw\n",
    "reddit = praw.Reddit(\n",
    "        client_id=APP_ID,\n",
    "        client_secret=SECRET,\n",
    "        user_agent=\"Comment Extraction\")\n",
    "\n",
    "# Set search parameters\n",
    "search_query = \"iPad\"\n",
    "max_comments = 1000\n",
    "\n",
    "# Initialize lists to store comment information\n",
    "comment_bodies = []\n",
    "comment_authors = []\n",
    "comment_upvotes = []\n",
    "comment_awards = []\n",
    "comment_dates = []\n",
    "\n",
    "# Set date range for comment extraction\n",
    "start_date = datetime(2022, 1, 1)\n",
    "end_date = datetime(2023, 11, 2)\n",
    "\n",
    "# Iterate through Reddit submissions containing the search query\n",
    "for submission in reddit.subreddit(\"all\").search(search_query, limit=max_comments):\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    for comment in submission.comments:\n",
    "        # Check if the comment is a root comment (not a reply)\n",
    "        if comment.is_root:\n",
    "            comment_date = datetime.utcfromtimestamp(comment.created_utc)\n",
    "            # Check if the comment is within the specified date range\n",
    "            if start_date <= comment_date <= end_date:\n",
    "                # Append relevant comment information to the lists\n",
    "                comment_bodies.append(comment.body)\n",
    "                comment_authors.append(comment.author.name if comment.author else \"[deleted]\")\n",
    "                comment_upvotes.append(comment.score)\n",
    "                comment_awards.append(comment.total_awards_received)\n",
    "                comment_dates.append(comment_date)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    \"Comment_Body\": comment_bodies,\n",
    "    \"Author\": comment_authors,\n",
    "    \"Upvotes\": comment_upvotes,\n",
    "    \"Awards\": comment_awards,\n",
    "    \"Date\": comment_dates,\n",
    "}\n",
    "\n",
    "temp_df = pd.DataFrame(data)\n",
    "\n",
    "# Data cleaning and filtering\n",
    "temp_df = temp_df[temp_df['Author'] != 'AutoModerator']\n",
    "temp_df = temp_df[temp_df['Comment_Body'] != '[deleted]']\n",
    "temp_df = temp_df[~temp_df['Comment_Body'].str.contains(r'\\[Banned for overrating\\]', case=False)]\n",
    "temp_df = temp_df[~temp_df['Comment_Body'].str.contains(r'\\br/\\w+', case=False)]\n",
    "temp_df = temp_df[temp_df['Comment_Body'].str.contains(\"iPad\", case=False)]\n",
    "temp_df = temp_df.dropna(subset=['Comment_Body'])\n",
    "\n",
    "# Add a column indicating the search term\n",
    "temp_df['Search'] = 'iPad'\n",
    "\n",
    "# Concatenate the temporary DataFrame with the main DataFrame\n",
    "df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "# Drop duplicate comments and save the final DataFrame to a CSV file\n",
    "df = df.dropna(subset=['Comment_Body']).drop_duplicates(subset=['Comment_Body'])\n",
    "df.to_csv('reddit_comments.csv', index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "030c91ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_Body</th>\n",
       "      <th>Author</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Awards</th>\n",
       "      <th>Date</th>\n",
       "      <th>Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Funny how Argentina isn't even on the list bec...</td>\n",
       "      <td>Yearlaren</td>\n",
       "      <td>3962</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 15:32:23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And just to add salt to the wound, iPhone in P...</td>\n",
       "      <td>pole_verme</td>\n",
       "      <td>1813</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 13:38:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I read a article saying that it was cheaper to...</td>\n",
       "      <td>_karma_bitch</td>\n",
       "      <td>1649</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 13:36:33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As a person that lived in the third world for ...</td>\n",
       "      <td>Momovsky</td>\n",
       "      <td>2851</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 12:40:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norwegian here. Number seems fairly accurate, ...</td>\n",
       "      <td>soffagrisen2</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-12 14:55:45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13667</th>\n",
       "      <td>Amazon LP won’t do anything, AirPods are not a...</td>\n",
       "      <td>GateKeeperJim</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-26 07:00:55</td>\n",
       "      <td>AirPods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13668</th>\n",
       "      <td>Fam I lost an AirPod and walked downstairs and...</td>\n",
       "      <td>Baron-Zsasz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-26 16:52:34</td>\n",
       "      <td>AirPods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13669</th>\n",
       "      <td>They were left unattended idk about stolen. Sa...</td>\n",
       "      <td>Jankylee-Ad-4453</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-27 19:29:54</td>\n",
       "      <td>AirPods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13670</th>\n",
       "      <td>I remember when my dog snatched one of my AirP...</td>\n",
       "      <td>FartzOnYaGyal</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-19 19:41:36</td>\n",
       "      <td>AirPods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13671</th>\n",
       "      <td>My puppy did this ate both AirPods and case I ...</td>\n",
       "      <td>brinicole323</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-19 23:01:15</td>\n",
       "      <td>AirPods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13667 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comment_Body            Author  \\\n",
       "0      Funny how Argentina isn't even on the list bec...         Yearlaren   \n",
       "1      And just to add salt to the wound, iPhone in P...        pole_verme   \n",
       "2      I read a article saying that it was cheaper to...      _karma_bitch   \n",
       "3      As a person that lived in the third world for ...          Momovsky   \n",
       "4      Norwegian here. Number seems fairly accurate, ...      soffagrisen2   \n",
       "...                                                  ...               ...   \n",
       "13667  Amazon LP won’t do anything, AirPods are not a...     GateKeeperJim   \n",
       "13668  Fam I lost an AirPod and walked downstairs and...       Baron-Zsasz   \n",
       "13669  They were left unattended idk about stolen. Sa...  Jankylee-Ad-4453   \n",
       "13670  I remember when my dog snatched one of my AirP...     FartzOnYaGyal   \n",
       "13671  My puppy did this ate both AirPods and case I ...      brinicole323   \n",
       "\n",
       "       Upvotes  Awards                Date   Search  \n",
       "0         3962       0 2022-09-12 15:32:23      NaN  \n",
       "1         1813       0 2022-09-12 13:38:00      NaN  \n",
       "2         1649       0 2022-09-12 13:36:33      NaN  \n",
       "3         2851       0 2022-09-12 12:40:50      NaN  \n",
       "4          181       0 2022-09-12 14:55:45      NaN  \n",
       "...        ...     ...                 ...      ...  \n",
       "13667       -2       0 2023-10-26 07:00:55  AirPods  \n",
       "13668        1       0 2023-10-26 16:52:34  AirPods  \n",
       "13669        1       0 2023-10-27 19:29:54  AirPods  \n",
       "13670       63       0 2023-03-19 19:41:36  AirPods  \n",
       "13671        3       0 2023-03-19 23:01:15  AirPods  \n",
       "\n",
       "[13667 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Reddit API credentials\n",
    "SECRET = \"fDTjgQd2sS6gmVrqm7IcPPhp05NHXg\"\n",
    "APP_ID = \"KGv2MMUcdlqidiWTIP4YPA\"\n",
    "\n",
    "# Authenticate with Reddit using praw\n",
    "reddit = praw.Reddit(\n",
    "        client_id=APP_ID,\n",
    "        client_secret=SECRET,\n",
    "        user_agent=\"Comment Extraction\")\n",
    "\n",
    "# Set search parameters\n",
    "search_query = \"AirPods\"\n",
    "max_comments = 1000\n",
    "\n",
    "# Initialize lists to store comment information\n",
    "comment_bodies = []\n",
    "comment_authors = []\n",
    "comment_upvotes = []\n",
    "comment_awards = []\n",
    "comment_dates = []\n",
    "\n",
    "# Set date range for comment extraction\n",
    "start_date = datetime(2022, 1, 1)\n",
    "end_date = datetime(2023, 11, 2)\n",
    "\n",
    "# Iterate through Reddit submissions containing the search query\n",
    "for submission in reddit.subreddit(\"all\").search(search_query, limit=max_comments):\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    for comment in submission.comments:\n",
    "        # Check if the comment is a root comment (not a reply)\n",
    "        if comment.is_root:\n",
    "            comment_date = datetime.utcfromtimestamp(comment.created_utc)\n",
    "            # Check if the comment is within the specified date range\n",
    "            if start_date <= comment_date <= end_date:\n",
    "                # Append relevant comment information to the lists\n",
    "                comment_bodies.append(comment.body)\n",
    "                comment_authors.append(comment.author.name if comment.author else \"[deleted]\")\n",
    "                comment_upvotes.append(comment.score)\n",
    "                comment_awards.append(comment.total_awards_received)\n",
    "                comment_dates.append(comment_date)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    \"Comment_Body\": comment_bodies,\n",
    "    \"Author\": comment_authors,\n",
    "    \"Upvotes\": comment_upvotes,\n",
    "    \"Awards\": comment_awards,\n",
    "    \"Date\": comment_dates,\n",
    "}\n",
    "\n",
    "temp_df = pd.DataFrame(data)\n",
    "\n",
    "# Data cleaning and filtering\n",
    "temp_df = temp_df[temp_df['Author'] != 'AutoModerator']\n",
    "temp_df = temp_df[temp_df['Comment_Body'] != '[deleted]']\n",
    "temp_df = temp_df[~temp_df['Comment_Body'].str.contains(r'\\[Banned for overrating\\]', case=False)]\n",
    "temp_df = temp_df[~temp_df['Comment_Body'].str.contains(r'\\br/\\w+', case=False)]\n",
    "temp_df = temp_df[temp_df['Comment_Body'].str.contains(\"AirPods\", case=False)]\n",
    "temp_df = temp_df.dropna(subset=['Comment_Body'])\n",
    "\n",
    "# Add a column indicating the search term\n",
    "temp_df['Search'] = 'AirPods'\n",
    "\n",
    "# Concatenate the temporary DataFrame with the main DataFrame\n",
    "# (Assuming 'df' is already defined elsewhere in the code)\n",
    "df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "# Drop duplicate comments and save the final DataFrame to a CSV file\n",
    "df = df.dropna(subset=['Comment_Body']).drop_duplicates(subset=['Comment_Body'])\n",
    "df.to_csv('reddit_comments.csv', index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "389e821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_Body</th>\n",
       "      <th>Author</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Awards</th>\n",
       "      <th>Date</th>\n",
       "      <th>Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’ve owned a smartwatch before, but at the end...</td>\n",
       "      <td>enunciate-candelabra</td>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-25 11:48:55</td>\n",
       "      <td>Apple Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Personally, for me, it was the battery life. I...</td>\n",
       "      <td>bottledmoons</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-25 14:06:36</td>\n",
       "      <td>Apple Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One year after I got my Apple Watch SE, the lo...</td>\n",
       "      <td>ColbyAndrew</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-25 12:02:44</td>\n",
       "      <td>Apple Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Before I retired from doing triathlons I prefe...</td>\n",
       "      <td>cuisinart-hatrack</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-25 11:53:40</td>\n",
       "      <td>Apple Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I still don't understand smart watches tbh</td>\n",
       "      <td>DontBanMeBro988</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-25 14:26:57</td>\n",
       "      <td>Apple Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4025</th>\n",
       "      <td>News about AirTag doing something: Apple is no...</td>\n",
       "      <td>paranoideo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31 20:25:36</td>\n",
       "      <td>Apple Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>An Apple Watch saving a persons life is WONDER...</td>\n",
       "      <td>Cohnman18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-01 00:40:05</td>\n",
       "      <td>Apple Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>now if only the apple watch can go at least 3 ...</td>\n",
       "      <td>SendMeAmazonGiftCard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-01 07:19:20</td>\n",
       "      <td>Apple Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>Can Samsung watches do this too?</td>\n",
       "      <td>MinerAlum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-01 09:26:00</td>\n",
       "      <td>Apple Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>Don’t get me wrong - this is an amazing story ...</td>\n",
       "      <td>PressFforAlderaan</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-01 18:20:04</td>\n",
       "      <td>Apple Watch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4022 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Comment_Body                Author  \\\n",
       "0     I’ve owned a smartwatch before, but at the end...  enunciate-candelabra   \n",
       "1     Personally, for me, it was the battery life. I...          bottledmoons   \n",
       "2     One year after I got my Apple Watch SE, the lo...           ColbyAndrew   \n",
       "3     Before I retired from doing triathlons I prefe...     cuisinart-hatrack   \n",
       "4            I still don't understand smart watches tbh       DontBanMeBro988   \n",
       "...                                                 ...                   ...   \n",
       "4025  News about AirTag doing something: Apple is no...            paranoideo   \n",
       "4026  An Apple Watch saving a persons life is WONDER...             Cohnman18   \n",
       "4027  now if only the apple watch can go at least 3 ...  SendMeAmazonGiftCard   \n",
       "4028                   Can Samsung watches do this too?             MinerAlum   \n",
       "4029  Don’t get me wrong - this is an amazing story ...     PressFforAlderaan   \n",
       "\n",
       "      Upvotes  Awards                Date       Search  \n",
       "0         506       0 2023-01-25 11:48:55  Apple Watch  \n",
       "1          31       0 2023-01-25 14:06:36  Apple Watch  \n",
       "2          35       0 2023-01-25 12:02:44  Apple Watch  \n",
       "3          58       0 2023-01-25 11:53:40  Apple Watch  \n",
       "4          11       0 2023-01-25 14:26:57  Apple Watch  \n",
       "...       ...     ...                 ...          ...  \n",
       "4025        1       0 2022-01-31 20:25:36  Apple Watch  \n",
       "4026        1       0 2022-02-01 00:40:05  Apple Watch  \n",
       "4027        1       0 2022-02-01 07:19:20  Apple Watch  \n",
       "4028        1       0 2022-02-01 09:26:00  Apple Watch  \n",
       "4029        1       0 2022-02-01 18:20:04  Apple Watch  \n",
       "\n",
       "[4022 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Reddit API credentials\n",
    "SECRET = \"fDTjgQd2sS6gmVrqm7IcPPhp05NHXg\"\n",
    "APP_ID = \"KGv2MMUcdlqidiWTIP4YPA\"\n",
    "\n",
    "# Authenticate with Reddit using praw\n",
    "reddit = praw.Reddit(\n",
    "        client_id=APP_ID,\n",
    "        client_secret=SECRET,\n",
    "        user_agent=\"Comment Extraction\")\n",
    "\n",
    "# Set search parameters\n",
    "search_query = \"Apple Watch\"\n",
    "max_comments = 1000\n",
    "\n",
    "# Initialize lists to store comment information\n",
    "comment_bodies = []\n",
    "comment_authors = []\n",
    "comment_upvotes = []\n",
    "comment_awards = []\n",
    "comment_dates = []\n",
    "\n",
    "# Set date range for comment extraction\n",
    "start_date = datetime(2022, 1, 1)\n",
    "end_date = datetime(2023, 11, 2)\n",
    "\n",
    "# Iterate through Reddit submissions containing the search query\n",
    "for submission in reddit.subreddit(\"all\").search(search_query, limit=max_comments):\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    for comment in submission.comments:\n",
    "        # Check if the comment is a root comment (not a reply)\n",
    "        if comment.is_root:\n",
    "            comment_date = datetime.utcfromtimestamp(comment.created_utc)\n",
    "            # Check if the comment is within the specified date range\n",
    "            if start_date <= comment_date <= end_date:\n",
    "                # Append relevant comment information to the lists\n",
    "                comment_bodies.append(comment.body)\n",
    "                comment_authors.append(comment.author.name if comment.author else \"[deleted]\")\n",
    "                comment_upvotes.append(comment.score)\n",
    "                comment_awards.append(comment.total_awards_received)\n",
    "                comment_dates.append(comment_date)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    \"Comment_Body\": comment_bodies,\n",
    "    \"Author\": comment_authors,\n",
    "    \"Upvotes\": comment_upvotes,\n",
    "    \"Awards\": comment_awards,\n",
    "    \"Date\": comment_dates,\n",
    "}\n",
    "\n",
    "temp_df = pd.DataFrame(data)\n",
    "\n",
    "# Data cleaning and filtering\n",
    "temp_df = temp_df[temp_df['Author'] != 'AutoModerator']\n",
    "temp_df = temp_df[temp_df['Comment_Body'] != '[deleted]']\n",
    "temp_df = temp_df[~temp_df['Comment_Body'].str.contains(r'\\[Banned for overrating\\]', case=False)]\n",
    "temp_df = temp_df[~temp_df['Comment_Body'].str.contains(r'\\br/\\w+', case=False)]\n",
    "temp_df = temp_df[temp_df['Comment_Body'].str.contains(\"Watch\", case=False)]\n",
    "temp_df = temp_df.dropna(subset=['Comment_Body'])\n",
    "\n",
    "# Add a column indicating the search term\n",
    "temp_df['Search'] = 'Apple Watch'\n",
    "\n",
    "# Concatenate the temporary DataFrame with the main DataFrame\n",
    "# (Assuming 'df' is already defined elsewhere in the code)\n",
    "df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "# Drop duplicate comments and save the final DataFrame to a CSV file\n",
    "df = df.dropna(subset=['Comment_Body']).drop_duplicates(subset=['Comment_Body'])\n",
    "df.to_csv('reddit_comments.csv', index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db39a849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPhone         7367\n",
       "Apple Watch    4551\n",
       "iPad           3382\n",
       "AirPods        1467\n",
       "Macbook        1451\n",
       "Name: Search, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the count of occurrences for each unique Apple product\n",
    "df.Search.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
